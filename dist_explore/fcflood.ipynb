{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pipeline for Training and Analysis of 20 2x100 FC models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from src.cifar.models import *\n",
    "from src.util import split_train_val, test, train, save_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# this should print 'cuda' if you are assigned a GPU\n",
    "print(device)\n",
    "\n",
    "train_batch_size = 100\n",
    "test_batch_size = 100\n",
    "n_epochs = 5\n",
    "learning_rate = 1e-2\n",
    "seed = 100\n",
    "input_dim = 32*32*3\n",
    "out_dim = 10\n",
    "num_hidden_layers = 2\n",
    "layer_size = 100\n",
    "momentum = 0.9\n",
    "weight_decay_lam = 1e-4\n",
    "\n",
    "fc_model_params = [(2,100)]*20\n",
    "\n",
    "complex_models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "training data size:50000\n",
      "test data size:10000\n"
     ]
    }
   ],
   "source": [
    "transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "train_dataset = torchvision.datasets.CIFAR10('./datasets/', train=True, download=True, transform=transforms)\n",
    "test_dataset = torchvision.datasets.CIFAR10('./datasets/', train=False, download=True, transform=transforms)\n",
    "\n",
    "raw_test_data = torchvision.datasets.CIFAR10('./datasets/', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "# sanity check\n",
    "print('training data size:{}'.format(len(train_dataset)))\n",
    "print('test data size:{}'.format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size:41667\n",
      "validation data size:8333\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = split_train_val(train_dataset, valid_ratio=1/6)\n",
    "print('training data size:{}'.format(len(train_dataset)))\n",
    "print('validation data size:{}'.format(len(val_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size:41667\n",
      "validation data size:8333\n",
      "test data size:10000\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=train_batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "raw_test_loader = torch.utils.data.DataLoader(raw_test_data, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "# sanity check\n",
    "print('training data size:{}'.format(len(train_loader.dataset)))\n",
    "print('validation data size:{}'.format(len(val_loader.dataset)))\n",
    "print('test data size:{}'.format(len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fc_models = [FC(input_dim, out_dim, num_hidden_layers, layer_size) for num_hidden_layers, layer_size in fc_model_params]\n",
    "complex_models = load_pretrained_models(complex_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "for i, model in enumerate(fc_models):\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay_lam)\n",
    "\n",
    "    print(\"Training FC model {}\".format(i+1))\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train(model, train_loader, optimizer, epoch, device)\n",
    "\n",
    "    test(model, val_loader, device)\n",
    "\n",
    "    print(\"Saving FC model: {}\".format(model))\n",
    "    save_model(model, dataset=\"CIFAR10\", filename=\"FC\" + str(i))\n",
    "\n",
    "for i, model in enumerate(os.listdir(\"./models/CIFAR10/\")):\n",
    "    if model.endswith(\".pth\") and \"FC\" in model:\n",
    "        fc_models[i].load_state_dict(torch.load(\"./models/CIFAR10/\" + model))\n",
    "        with torch.no_grad():\n",
    "            test(fc_models[i].to(device), test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Missclassification Tracking\n",
    "\n",
    "Images tracked as tuples (batch_idx, image_idx) and can be accessed from dataset as test_dataset[batch_idx][image_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed 4871/10000\n",
      "Missed 9894/10000\n",
      "Missed 14886/10000\n",
      "Missed 19874/10000\n",
      "Missed 24849/10000\n",
      "Missed 29735/10000\n",
      "Missed 34678/10000\n",
      "Missed 39683/10000\n",
      "Missed 44589/10000\n",
      "Missed 49469/10000\n",
      "Missed 54380/10000\n",
      "Missed 59297/10000\n",
      "Missed 64222/10000\n",
      "Missed 69133/10000\n",
      "Missed 74166/10000\n",
      "Missed 79189/10000\n",
      "Missed 84178/10000\n",
      "Missed 89145/10000\n",
      "Missed 94159/10000\n",
      "Missed 99073/10000\n"
     ]
    }
   ],
   "source": [
    "misses = dict()\n",
    "complex_list = list(complex_models.values())\n",
    "for model in fc_models + complex_list:\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i, (data, target) in enumerate(test_loader):\n",
    "\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "            missed = pred.not_equal(target.data.view_as(pred)).view(-1).cpu().numpy()\n",
    "\n",
    "            for j, miss in enumerate(missed):\n",
    "                if miss:\n",
    "                    if (i, j) in misses:\n",
    "                        misses[(i, j)] += 1\n",
    "                    else:\n",
    "                        misses[(i, j)] = 1\n",
    "\n",
    "print(\"Missed {}/{}\".format(sum(misses.values()), len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1634\n",
      "8277\n"
     ]
    }
   ],
   "source": [
    "all_miss = {k: v for k, v in misses.items() if v > 0}\n",
    "significant = {k: v for k, v in misses.items() if v > 19}\n",
    "print(len(significant))\n",
    "print(len(all_miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = list(all_miss.values()) + [0]*(len(test_dataset)-len(all_miss))\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8), facecolor=\"w\")\n",
    "plt.hist(y, [x-0.5 for x in range(22)], edgecolor=\"k\")\n",
    "plt.xlabel(\"Number of Missclassifications\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"plots/CIFAR10/im_freq.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for sample in significant:\\n\\n    idx = sample[0]*test_batch_size + sample[1]\\n    im_net = test_loader.dataset[idx][0].view(3, 32, 32)\\n    im_raw = raw_test_loader.dataset[idx][0].view(3, 32, 32)\\n    label = test_loader.dataset[idx][1]\\n\\n    preds = np.array([model(im_net.unsqueeze(0).to(device)).argmax(dim=1, keepdim=True).cpu().numpy() for model in fc_models + complex_list]).flatten()\\n    fig = plt.figure(figsize=(12, 8), facecolor=\"w\")\\n    plt.hist(preds, [x-0.5 for x in range(11)], edgecolor=\"k\")\\n    plt.xlabel(\"Predicted Label\")\\n    plt.ylabel(\"Frequency\")\\n    plt.title(\"True Label: {}\".format(label))\\n    plt.savefig(\"plots/CIFAR/images/im_\" + str(idx) + \"_freq.png\")\\n    plt.close()\\n\\n    fig = plt.figure()\\n    plt.imshow(im_raw.squeeze().cpu().numpy().transpose((1,2,0)))\\n    plt.title(\"Actual: {}\".format(test_loader.dataset.targets[idx]))\\n    plt.savefig(\"plots/CIFAR/images/im_\" + str(idx) + \".png\")\\n    plt.close()'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for sample in significant:\n",
    "\n",
    "    idx = sample[0]*test_batch_size + sample[1]\n",
    "    im_net = test_loader.dataset[idx][0].view(3, 32, 32)\n",
    "    im_raw = raw_test_loader.dataset[idx][0].view(3, 32, 32)\n",
    "    label = test_loader.dataset[idx][1]\n",
    "\n",
    "    preds = np.array([model(im_net.unsqueeze(0).to(device)).argmax(dim=1, keepdim=True).cpu().numpy() for model in fc_models + complex_list]).flatten()\n",
    "    fig = plt.figure(figsize=(12, 8), facecolor=\"w\")\n",
    "    plt.hist(preds, [x-0.5 for x in range(11)], edgecolor=\"k\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"True Label: {}\".format(label))\n",
    "    plt.savefig(\"plots/CIFAR10/images/im_\" + str(idx) + \"_freq.png\")\n",
    "    plt.close()\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(im_raw.squeeze().cpu().numpy().transpose((1,2,0)))\n",
    "    plt.title(\"Actual: {}\".format(test_loader.dataset.targets[idx]))\n",
    "    plt.savefig(\"plots/CIFAR10/images/im_\" + str(idx) + \".png\")\n",
    "    plt.close()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Changes\n",
    "\n",
    "- add 0 bin on hist\n",
    "- try cifar10.1\n",
    "- regularize FCs (remove overfit)\n",
    "    - weight decay\n",
    "    - dropout (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcc5ac7d8f588717dbbf943c8b5bdb493897677a8eb87de82c568242f51169a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}