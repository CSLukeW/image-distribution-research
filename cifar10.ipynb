{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for Training and Collection of MNIST Missclassifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from src.cifar.models import *\n",
    "from src.util import split_train_val, test, train, save_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# this should print 'cuda' if you are assigned a GPU\n",
    "print(device)\n",
    "\n",
    "train_batch_size = 100\n",
    "test_batch_size = 100\n",
    "n_epochs = 25\n",
    "learning_rate = 1e-2\n",
    "seed = 100\n",
    "input_dim = 32*32*3\n",
    "out_dim = 10\n",
    "num_hidden_layers = 2\n",
    "layer_size = 100\n",
    "momentum = 0.9\n",
    "\n",
    "fc_model_params = [\n",
    "    (2, 100),\n",
    "    (2, 200),\n",
    "    (3, 100),\n",
    "    (3, 200),\n",
    "    (4, 100),\n",
    "    (4, 200),\n",
    "]\n",
    "\n",
    "complex_models = [\n",
    "    \"cifar10_resnet20\",\n",
    "    \"cifar10_vgg11_bn\",\n",
    "    \"cifar10_mobilenetv2_x0_5\",\n",
    "    \"cifar10_shufflenetv2_x0_5\",\n",
    "    \"cifar10_repvgg_a0\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "training data size:50000\n",
      "test data size:10000\n"
     ]
    }
   ],
   "source": [
    "transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "train_dataset = torchvision.datasets.CIFAR10('./datasets/', train=True, download=True, transform=transforms)\n",
    "test_dataset = torchvision.datasets.CIFAR10('./datasets/', train=False, download=True, transform=transforms)\n",
    "\n",
    "raw_test_data = torchvision.datasets.CIFAR10('./datasets/', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "# sanity check\n",
    "print('training data size:{}'.format(len(train_dataset)))\n",
    "print('test data size:{}'.format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size:41667\n",
      "validation data size:8333\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = split_train_val(train_dataset, valid_ratio=1/6)\n",
    "print('training data size:{}'.format(len(train_dataset)))\n",
    "print('validation data size:{}'.format(len(val_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size:41667\n",
      "validation data size:8333\n",
      "test data size:10000\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=train_batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "raw_test_loader = torch.utils.data.DataLoader(raw_test_data, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "# sanity check\n",
    "print('training data size:{}'.format(len(train_loader.dataset)))\n",
    "print('validation data size:{}'.format(len(val_loader.dataset)))\n",
    "print('test data size:{}'.format(len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\willi/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n",
      "Using cache found in C:\\Users\\willi/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n",
      "Using cache found in C:\\Users\\willi/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n",
      "Using cache found in C:\\Users\\willi/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n",
      "Using cache found in C:\\Users\\willi/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "fc_models = [FC(input_dim, out_dim, num_hidden_layers, layer_size) for num_hidden_layers, layer_size in fc_model_params]\n",
    "complex_models = load_pretrained_models(complex_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training FC model: FC(\n",
      "  (layer_list): ModuleList(\n",
      "    (0): Linear(in_features=3072, out_features=100, bias=True)\n",
      "    (1): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Train Epoch: 1 [0/41667 (0%)]\tLoss: 2.297430\n",
      "\n",
      "Train Epoch: 1 [10000/41667 (24%)]\tLoss: 1.755133\n",
      "\n",
      "Train Epoch: 1 [20000/41667 (48%)]\tLoss: 1.481259\n",
      "\n",
      "Train Epoch: 1 [30000/41667 (72%)]\tLoss: 1.652415\n",
      "\n",
      "Train Epoch: 1 [40000/41667 (96%)]\tLoss: 1.505349\n",
      "\tAccuracy: 38.47%\n",
      "\n",
      "Train Epoch: 2 [0/41667 (0%)]\tLoss: 1.527683\n",
      "\n",
      "Train Epoch: 2 [10000/41667 (24%)]\tLoss: 1.559363\n",
      "\n",
      "Train Epoch: 2 [20000/41667 (48%)]\tLoss: 1.583312\n",
      "\n",
      "Train Epoch: 2 [30000/41667 (72%)]\tLoss: 1.399618\n",
      "\n",
      "Train Epoch: 2 [40000/41667 (96%)]\tLoss: 1.407522\n",
      "\tAccuracy: 47.07%\n",
      "\n",
      "Train Epoch: 3 [0/41667 (0%)]\tLoss: 1.381524\n",
      "\n",
      "Train Epoch: 3 [10000/41667 (24%)]\tLoss: 1.589507\n",
      "\n",
      "Train Epoch: 3 [20000/41667 (48%)]\tLoss: 1.330586\n",
      "\n",
      "Train Epoch: 3 [30000/41667 (72%)]\tLoss: 1.342534\n",
      "\n",
      "Train Epoch: 3 [40000/41667 (96%)]\tLoss: 1.224889\n",
      "\tAccuracy: 50.37%\n",
      "\n",
      "Train Epoch: 4 [0/41667 (0%)]\tLoss: 1.308530\n",
      "\n",
      "Train Epoch: 4 [10000/41667 (24%)]\tLoss: 1.374373\n",
      "\n",
      "Train Epoch: 4 [20000/41667 (48%)]\tLoss: 1.513586\n",
      "\n",
      "Train Epoch: 4 [30000/41667 (72%)]\tLoss: 1.196744\n",
      "\n",
      "Train Epoch: 4 [40000/41667 (96%)]\tLoss: 1.319983\n",
      "\tAccuracy: 52.99%\n",
      "\n",
      "Train Epoch: 5 [0/41667 (0%)]\tLoss: 1.181960\n",
      "\n",
      "Train Epoch: 5 [10000/41667 (24%)]\tLoss: 1.390911\n",
      "\n",
      "Train Epoch: 5 [20000/41667 (48%)]\tLoss: 1.330742\n",
      "\n",
      "Train Epoch: 5 [30000/41667 (72%)]\tLoss: 1.095291\n",
      "\n",
      "Train Epoch: 5 [40000/41667 (96%)]\tLoss: 1.227250\n",
      "\tAccuracy: 55.04%\n",
      "\n",
      "Train Epoch: 6 [0/41667 (0%)]\tLoss: 1.277529\n",
      "\n",
      "Train Epoch: 6 [10000/41667 (24%)]\tLoss: 1.315312\n",
      "\n",
      "Train Epoch: 6 [20000/41667 (48%)]\tLoss: 1.198461\n",
      "\n",
      "Train Epoch: 6 [30000/41667 (72%)]\tLoss: 1.356905\n",
      "\n",
      "Train Epoch: 6 [40000/41667 (96%)]\tLoss: 1.141176\n",
      "\tAccuracy: 56.76%\n",
      "\n",
      "Train Epoch: 7 [0/41667 (0%)]\tLoss: 1.197050\n",
      "\n",
      "Train Epoch: 7 [10000/41667 (24%)]\tLoss: 1.145044\n",
      "\n",
      "Train Epoch: 7 [20000/41667 (48%)]\tLoss: 1.209494\n",
      "\n",
      "Train Epoch: 7 [30000/41667 (72%)]\tLoss: 1.150405\n",
      "\n",
      "Train Epoch: 7 [40000/41667 (96%)]\tLoss: 1.124498\n",
      "\tAccuracy: 58.47%\n",
      "\n",
      "Train Epoch: 8 [0/41667 (0%)]\tLoss: 1.213410\n",
      "\n",
      "Train Epoch: 8 [10000/41667 (24%)]\tLoss: 0.955148\n",
      "\n",
      "Train Epoch: 8 [20000/41667 (48%)]\tLoss: 1.167076\n",
      "\n",
      "Train Epoch: 8 [30000/41667 (72%)]\tLoss: 1.100283\n",
      "\n",
      "Train Epoch: 8 [40000/41667 (96%)]\tLoss: 1.205592\n",
      "\tAccuracy: 60.00%\n",
      "\n",
      "Train Epoch: 9 [0/41667 (0%)]\tLoss: 1.139030\n",
      "\n",
      "Train Epoch: 9 [10000/41667 (24%)]\tLoss: 1.174895\n",
      "\n",
      "Train Epoch: 9 [20000/41667 (48%)]\tLoss: 1.140458\n",
      "\n",
      "Train Epoch: 9 [30000/41667 (72%)]\tLoss: 1.216280\n",
      "\n",
      "Train Epoch: 9 [40000/41667 (96%)]\tLoss: 0.999038\n",
      "\tAccuracy: 61.17%\n",
      "\n",
      "Train Epoch: 10 [0/41667 (0%)]\tLoss: 0.982568\n",
      "\n",
      "Train Epoch: 10 [10000/41667 (24%)]\tLoss: 1.149051\n",
      "\n",
      "Train Epoch: 10 [20000/41667 (48%)]\tLoss: 1.096881\n",
      "\n",
      "Train Epoch: 10 [30000/41667 (72%)]\tLoss: 1.092362\n",
      "\n",
      "Train Epoch: 10 [40000/41667 (96%)]\tLoss: 0.839270\n",
      "\tAccuracy: 62.23%\n",
      "\n",
      "Train Epoch: 11 [0/41667 (0%)]\tLoss: 0.894261\n",
      "\n",
      "Train Epoch: 11 [10000/41667 (24%)]\tLoss: 0.907419\n",
      "\n",
      "Train Epoch: 11 [20000/41667 (48%)]\tLoss: 1.186702\n",
      "\n",
      "Train Epoch: 11 [30000/41667 (72%)]\tLoss: 1.042671\n",
      "\n",
      "Train Epoch: 11 [40000/41667 (96%)]\tLoss: 1.003534\n",
      "\tAccuracy: 63.45%\n",
      "\n",
      "Train Epoch: 12 [0/41667 (0%)]\tLoss: 1.041920\n",
      "\n",
      "Train Epoch: 12 [10000/41667 (24%)]\tLoss: 0.946118\n",
      "\n",
      "Train Epoch: 12 [20000/41667 (48%)]\tLoss: 1.146562\n",
      "\n",
      "Train Epoch: 12 [30000/41667 (72%)]\tLoss: 1.135759\n",
      "\n",
      "Train Epoch: 12 [40000/41667 (96%)]\tLoss: 1.148228\n",
      "\tAccuracy: 64.44%\n",
      "\n",
      "Train Epoch: 13 [0/41667 (0%)]\tLoss: 0.933990\n",
      "\n",
      "Train Epoch: 13 [10000/41667 (24%)]\tLoss: 1.026519\n",
      "\n",
      "Train Epoch: 13 [20000/41667 (48%)]\tLoss: 0.814453\n",
      "\n",
      "Train Epoch: 13 [30000/41667 (72%)]\tLoss: 1.060173\n",
      "\n",
      "Train Epoch: 13 [40000/41667 (96%)]\tLoss: 0.893912\n",
      "\tAccuracy: 65.46%\n",
      "\n",
      "Train Epoch: 14 [0/41667 (0%)]\tLoss: 1.016616\n",
      "\n",
      "Train Epoch: 14 [10000/41667 (24%)]\tLoss: 0.846715\n",
      "\n",
      "Train Epoch: 14 [20000/41667 (48%)]\tLoss: 0.895158\n",
      "\n",
      "Train Epoch: 14 [30000/41667 (72%)]\tLoss: 0.815952\n",
      "\n",
      "Train Epoch: 14 [40000/41667 (96%)]\tLoss: 1.066719\n",
      "\tAccuracy: 66.28%\n",
      "\n",
      "Train Epoch: 15 [0/41667 (0%)]\tLoss: 0.936560\n",
      "\n",
      "Train Epoch: 15 [10000/41667 (24%)]\tLoss: 1.069905\n",
      "\n",
      "Train Epoch: 15 [20000/41667 (48%)]\tLoss: 0.985147\n",
      "\n",
      "Train Epoch: 15 [30000/41667 (72%)]\tLoss: 0.900582\n",
      "\n",
      "Train Epoch: 15 [40000/41667 (96%)]\tLoss: 0.873661\n",
      "\tAccuracy: 67.23%\n",
      "\n",
      "Train Epoch: 16 [0/41667 (0%)]\tLoss: 0.721788\n",
      "\n",
      "Train Epoch: 16 [10000/41667 (24%)]\tLoss: 0.719532\n",
      "\n",
      "Train Epoch: 16 [20000/41667 (48%)]\tLoss: 0.905544\n",
      "\n",
      "Train Epoch: 16 [30000/41667 (72%)]\tLoss: 0.756176\n",
      "\n",
      "Train Epoch: 16 [40000/41667 (96%)]\tLoss: 1.129618\n",
      "\tAccuracy: 68.17%\n",
      "\n",
      "Train Epoch: 17 [0/41667 (0%)]\tLoss: 0.802726\n",
      "\n",
      "Train Epoch: 17 [10000/41667 (24%)]\tLoss: 0.712211\n",
      "\n",
      "Train Epoch: 17 [20000/41667 (48%)]\tLoss: 0.932136\n",
      "\n",
      "Train Epoch: 17 [30000/41667 (72%)]\tLoss: 1.040002\n",
      "\n",
      "Train Epoch: 17 [40000/41667 (96%)]\tLoss: 0.888423\n",
      "\tAccuracy: 68.62%\n",
      "\n",
      "Train Epoch: 18 [0/41667 (0%)]\tLoss: 0.666372\n",
      "\n",
      "Train Epoch: 18 [10000/41667 (24%)]\tLoss: 0.854664\n",
      "\n",
      "Train Epoch: 18 [20000/41667 (48%)]\tLoss: 0.935753\n",
      "\n",
      "Train Epoch: 18 [30000/41667 (72%)]\tLoss: 1.028739\n",
      "\n",
      "Train Epoch: 18 [40000/41667 (96%)]\tLoss: 0.878707\n",
      "\tAccuracy: 69.39%\n",
      "\n",
      "Train Epoch: 19 [0/41667 (0%)]\tLoss: 0.845098\n",
      "\n",
      "Train Epoch: 19 [10000/41667 (24%)]\tLoss: 0.986364\n",
      "\n",
      "Train Epoch: 19 [20000/41667 (48%)]\tLoss: 0.733820\n",
      "\n",
      "Train Epoch: 19 [30000/41667 (72%)]\tLoss: 0.976145\n",
      "\n",
      "Train Epoch: 19 [40000/41667 (96%)]\tLoss: 0.891146\n",
      "\tAccuracy: 70.68%\n",
      "\n",
      "Train Epoch: 20 [0/41667 (0%)]\tLoss: 0.808439\n",
      "\n",
      "Train Epoch: 20 [10000/41667 (24%)]\tLoss: 0.766538\n",
      "\n",
      "Train Epoch: 20 [20000/41667 (48%)]\tLoss: 0.738923\n",
      "\n",
      "Train Epoch: 20 [30000/41667 (72%)]\tLoss: 0.847528\n",
      "\n",
      "Train Epoch: 20 [40000/41667 (96%)]\tLoss: 0.954529\n",
      "\tAccuracy: 71.06%\n",
      "\n",
      "Train Epoch: 21 [0/41667 (0%)]\tLoss: 0.559321\n",
      "\n",
      "Train Epoch: 21 [10000/41667 (24%)]\tLoss: 0.674243\n",
      "\n",
      "Train Epoch: 21 [20000/41667 (48%)]\tLoss: 0.718361\n",
      "\n",
      "Train Epoch: 21 [30000/41667 (72%)]\tLoss: 0.942660\n",
      "\n",
      "Train Epoch: 21 [40000/41667 (96%)]\tLoss: 0.868586\n",
      "\tAccuracy: 71.85%\n",
      "\n",
      "Train Epoch: 22 [0/41667 (0%)]\tLoss: 0.679189\n",
      "\n",
      "Train Epoch: 22 [10000/41667 (24%)]\tLoss: 0.590761\n",
      "\n",
      "Train Epoch: 22 [20000/41667 (48%)]\tLoss: 0.664910\n",
      "\n",
      "Train Epoch: 22 [30000/41667 (72%)]\tLoss: 0.739560\n",
      "\n",
      "Train Epoch: 22 [40000/41667 (96%)]\tLoss: 0.691980\n",
      "\tAccuracy: 72.41%\n",
      "\n",
      "Train Epoch: 23 [0/41667 (0%)]\tLoss: 0.620435\n",
      "\n",
      "Train Epoch: 23 [10000/41667 (24%)]\tLoss: 0.689469\n",
      "\n",
      "Train Epoch: 23 [20000/41667 (48%)]\tLoss: 0.796192\n",
      "\n",
      "Train Epoch: 23 [30000/41667 (72%)]\tLoss: 0.718994\n",
      "\n",
      "Train Epoch: 23 [40000/41667 (96%)]\tLoss: 0.875085\n",
      "\tAccuracy: 72.78%\n",
      "\n",
      "Train Epoch: 24 [0/41667 (0%)]\tLoss: 0.684913\n",
      "\n",
      "Train Epoch: 24 [10000/41667 (24%)]\tLoss: 0.702678\n",
      "\n",
      "Train Epoch: 24 [20000/41667 (48%)]\tLoss: 0.656721\n",
      "\n",
      "Train Epoch: 24 [30000/41667 (72%)]\tLoss: 0.874034\n",
      "\n",
      "Train Epoch: 24 [40000/41667 (96%)]\tLoss: 0.628040\n",
      "\tAccuracy: 73.54%\n",
      "\n",
      "Train Epoch: 25 [0/41667 (0%)]\tLoss: 0.504028\n",
      "\n",
      "Train Epoch: 25 [10000/41667 (24%)]\tLoss: 0.620894\n",
      "\n",
      "Train Epoch: 25 [20000/41667 (48%)]\tLoss: 0.812740\n",
      "\n",
      "Train Epoch: 25 [30000/41667 (72%)]\tLoss: 0.715728\n",
      "\n",
      "Train Epoch: 25 [40000/41667 (96%)]\tLoss: 0.732121\n",
      "\tAccuracy: 73.69%\n",
      "Test set: Avg. loss: -467.9237, Accuracy: 4140/8333 (49.68%)\n",
      "Saving FC model: FC(\n",
      "  (layer_list): ModuleList(\n",
      "    (0): Linear(in_features=3072, out_features=100, bias=True)\n",
      "    (1): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Training FC model: FC(\n",
      "  (layer_list): ModuleList(\n",
      "    (0): Linear(in_features=3072, out_features=200, bias=True)\n",
      "    (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Train Epoch: 1 [0/41667 (0%)]\tLoss: 2.306034\n",
      "\n",
      "Train Epoch: 1 [10000/41667 (24%)]\tLoss: 1.726021\n",
      "\n",
      "Train Epoch: 1 [20000/41667 (48%)]\tLoss: 1.552070\n",
      "\n",
      "Train Epoch: 1 [30000/41667 (72%)]\tLoss: 1.682934\n",
      "\n",
      "Train Epoch: 1 [40000/41667 (96%)]\tLoss: 1.490372\n",
      "\tAccuracy: 38.98%\n",
      "\n",
      "Train Epoch: 2 [0/41667 (0%)]\tLoss: 1.344452\n",
      "\n",
      "Train Epoch: 2 [10000/41667 (24%)]\tLoss: 1.493866\n",
      "\n",
      "Train Epoch: 2 [20000/41667 (48%)]\tLoss: 1.525097\n",
      "\n",
      "Train Epoch: 2 [30000/41667 (72%)]\tLoss: 1.418890\n",
      "\n",
      "Train Epoch: 2 [40000/41667 (96%)]\tLoss: 1.554223\n",
      "\tAccuracy: 47.96%\n",
      "\n",
      "Train Epoch: 3 [0/41667 (0%)]\tLoss: 1.503539\n",
      "\n",
      "Train Epoch: 3 [10000/41667 (24%)]\tLoss: 1.356414\n",
      "\n",
      "Train Epoch: 3 [20000/41667 (48%)]\tLoss: 1.083810\n",
      "\n",
      "Train Epoch: 3 [30000/41667 (72%)]\tLoss: 1.130334\n",
      "\n",
      "Train Epoch: 3 [40000/41667 (96%)]\tLoss: 1.232272\n",
      "\tAccuracy: 52.07%\n",
      "\n",
      "Train Epoch: 4 [0/41667 (0%)]\tLoss: 1.077163\n",
      "\n",
      "Train Epoch: 4 [10000/41667 (24%)]\tLoss: 1.199973\n",
      "\n",
      "Train Epoch: 4 [20000/41667 (48%)]\tLoss: 1.291624\n",
      "\n",
      "Train Epoch: 4 [30000/41667 (72%)]\tLoss: 1.132116\n",
      "\n",
      "Train Epoch: 4 [40000/41667 (96%)]\tLoss: 1.352232\n",
      "\tAccuracy: 55.21%\n",
      "\n",
      "Train Epoch: 5 [0/41667 (0%)]\tLoss: 1.072704\n",
      "\n",
      "Train Epoch: 5 [10000/41667 (24%)]\tLoss: 1.086343\n",
      "\n",
      "Train Epoch: 5 [20000/41667 (48%)]\tLoss: 1.334500\n",
      "\n",
      "Train Epoch: 5 [30000/41667 (72%)]\tLoss: 1.375503\n",
      "\n",
      "Train Epoch: 5 [40000/41667 (96%)]\tLoss: 1.066480\n",
      "\tAccuracy: 57.40%\n",
      "\n",
      "Train Epoch: 6 [0/41667 (0%)]\tLoss: 1.149730\n",
      "\n",
      "Train Epoch: 6 [10000/41667 (24%)]\tLoss: 1.138452\n",
      "\n",
      "Train Epoch: 6 [20000/41667 (48%)]\tLoss: 1.326439\n",
      "\n",
      "Train Epoch: 6 [30000/41667 (72%)]\tLoss: 1.109415\n",
      "\n",
      "Train Epoch: 6 [40000/41667 (96%)]\tLoss: 1.270786\n",
      "\tAccuracy: 59.69%\n",
      "\n",
      "Train Epoch: 7 [0/41667 (0%)]\tLoss: 1.171867\n",
      "\n",
      "Train Epoch: 7 [10000/41667 (24%)]\tLoss: 1.225678\n",
      "\n",
      "Train Epoch: 7 [20000/41667 (48%)]\tLoss: 1.053762\n",
      "\n",
      "Train Epoch: 7 [30000/41667 (72%)]\tLoss: 0.959872\n",
      "\n",
      "Train Epoch: 7 [40000/41667 (96%)]\tLoss: 1.146768\n",
      "\tAccuracy: 61.89%\n",
      "\n",
      "Train Epoch: 8 [0/41667 (0%)]\tLoss: 0.965895\n",
      "\n",
      "Train Epoch: 8 [10000/41667 (24%)]\tLoss: 1.075838\n",
      "\n",
      "Train Epoch: 8 [20000/41667 (48%)]\tLoss: 1.089740\n",
      "\n",
      "Train Epoch: 8 [30000/41667 (72%)]\tLoss: 1.071797\n",
      "\n",
      "Train Epoch: 8 [40000/41667 (96%)]\tLoss: 1.056319\n",
      "\tAccuracy: 64.06%\n",
      "\n",
      "Train Epoch: 9 [0/41667 (0%)]\tLoss: 0.855418\n",
      "\n",
      "Train Epoch: 9 [10000/41667 (24%)]\tLoss: 0.988867\n",
      "\n",
      "Train Epoch: 9 [20000/41667 (48%)]\tLoss: 1.125723\n",
      "\n",
      "Train Epoch: 9 [30000/41667 (72%)]\tLoss: 0.768182\n",
      "\n",
      "Train Epoch: 9 [40000/41667 (96%)]\tLoss: 0.955448\n",
      "\tAccuracy: 65.39%\n",
      "\n",
      "Train Epoch: 10 [0/41667 (0%)]\tLoss: 0.743535\n",
      "\n",
      "Train Epoch: 10 [10000/41667 (24%)]\tLoss: 0.889342\n",
      "\n",
      "Train Epoch: 10 [20000/41667 (48%)]\tLoss: 0.867571\n",
      "\n",
      "Train Epoch: 10 [30000/41667 (72%)]\tLoss: 1.070775\n",
      "\n",
      "Train Epoch: 10 [40000/41667 (96%)]\tLoss: 1.142892\n",
      "\tAccuracy: 67.41%\n",
      "\n",
      "Train Epoch: 11 [0/41667 (0%)]\tLoss: 0.863812\n",
      "\n",
      "Train Epoch: 11 [10000/41667 (24%)]\tLoss: 0.679546\n",
      "\n",
      "Train Epoch: 11 [20000/41667 (48%)]\tLoss: 0.806852\n",
      "\n",
      "Train Epoch: 11 [30000/41667 (72%)]\tLoss: 1.017844\n",
      "\n",
      "Train Epoch: 11 [40000/41667 (96%)]\tLoss: 0.895195\n",
      "\tAccuracy: 69.20%\n",
      "\n",
      "Train Epoch: 12 [0/41667 (0%)]\tLoss: 0.719060\n",
      "\n",
      "Train Epoch: 12 [10000/41667 (24%)]\tLoss: 0.706163\n",
      "\n",
      "Train Epoch: 12 [20000/41667 (48%)]\tLoss: 0.772093\n",
      "\n",
      "Train Epoch: 12 [30000/41667 (72%)]\tLoss: 1.003095\n",
      "\n",
      "Train Epoch: 12 [40000/41667 (96%)]\tLoss: 0.863619\n",
      "\tAccuracy: 70.46%\n",
      "\n",
      "Train Epoch: 13 [0/41667 (0%)]\tLoss: 0.734952\n",
      "\n",
      "Train Epoch: 13 [10000/41667 (24%)]\tLoss: 0.773522\n",
      "\n",
      "Train Epoch: 13 [20000/41667 (48%)]\tLoss: 0.825866\n",
      "\n",
      "Train Epoch: 13 [30000/41667 (72%)]\tLoss: 0.726417\n",
      "\n",
      "Train Epoch: 13 [40000/41667 (96%)]\tLoss: 0.962268\n",
      "\tAccuracy: 72.19%\n",
      "\n",
      "Train Epoch: 14 [0/41667 (0%)]\tLoss: 0.726042\n",
      "\n",
      "Train Epoch: 14 [10000/41667 (24%)]\tLoss: 0.822970\n",
      "\n",
      "Train Epoch: 14 [20000/41667 (48%)]\tLoss: 0.647877\n",
      "\n",
      "Train Epoch: 14 [30000/41667 (72%)]\tLoss: 0.763989\n",
      "\n",
      "Train Epoch: 14 [40000/41667 (96%)]\tLoss: 0.497555\n",
      "\tAccuracy: 73.69%\n",
      "\n",
      "Train Epoch: 15 [0/41667 (0%)]\tLoss: 0.633639\n",
      "\n",
      "Train Epoch: 15 [10000/41667 (24%)]\tLoss: 0.608544\n",
      "\n",
      "Train Epoch: 15 [20000/41667 (48%)]\tLoss: 0.702736\n",
      "\n",
      "Train Epoch: 15 [30000/41667 (72%)]\tLoss: 0.783953\n",
      "\n",
      "Train Epoch: 15 [40000/41667 (96%)]\tLoss: 0.728386\n",
      "\tAccuracy: 75.22%\n",
      "\n",
      "Train Epoch: 16 [0/41667 (0%)]\tLoss: 0.551122\n",
      "\n",
      "Train Epoch: 16 [10000/41667 (24%)]\tLoss: 0.639355\n",
      "\n",
      "Train Epoch: 16 [20000/41667 (48%)]\tLoss: 0.500365\n",
      "\n",
      "Train Epoch: 16 [30000/41667 (72%)]\tLoss: 0.699104\n",
      "\n",
      "Train Epoch: 16 [40000/41667 (96%)]\tLoss: 0.813370\n",
      "\tAccuracy: 76.37%\n",
      "\n",
      "Train Epoch: 17 [0/41667 (0%)]\tLoss: 0.657633\n",
      "\n",
      "Train Epoch: 17 [10000/41667 (24%)]\tLoss: 0.575822\n",
      "\n",
      "Train Epoch: 17 [20000/41667 (48%)]\tLoss: 0.898225\n",
      "\n",
      "Train Epoch: 17 [30000/41667 (72%)]\tLoss: 0.521151\n",
      "\n",
      "Train Epoch: 17 [40000/41667 (96%)]\tLoss: 0.473608\n",
      "\tAccuracy: 77.79%\n",
      "\n",
      "Train Epoch: 18 [0/41667 (0%)]\tLoss: 0.506454\n",
      "\n",
      "Train Epoch: 18 [10000/41667 (24%)]\tLoss: 0.511659\n",
      "\n",
      "Train Epoch: 18 [20000/41667 (48%)]\tLoss: 0.618306\n",
      "\n",
      "Train Epoch: 18 [30000/41667 (72%)]\tLoss: 0.731582\n",
      "\n",
      "Train Epoch: 18 [40000/41667 (96%)]\tLoss: 0.687693\n",
      "\tAccuracy: 78.59%\n",
      "\n",
      "Train Epoch: 19 [0/41667 (0%)]\tLoss: 0.565143\n",
      "\n",
      "Train Epoch: 19 [10000/41667 (24%)]\tLoss: 0.557110\n",
      "\n",
      "Train Epoch: 19 [20000/41667 (48%)]\tLoss: 0.516891\n",
      "\n",
      "Train Epoch: 19 [30000/41667 (72%)]\tLoss: 0.640179\n",
      "\n",
      "Train Epoch: 19 [40000/41667 (96%)]\tLoss: 0.777087\n",
      "\tAccuracy: 80.09%\n",
      "\n",
      "Train Epoch: 20 [0/41667 (0%)]\tLoss: 0.448840\n",
      "\n",
      "Train Epoch: 20 [10000/41667 (24%)]\tLoss: 0.342812\n",
      "\n",
      "Train Epoch: 20 [20000/41667 (48%)]\tLoss: 0.771776\n",
      "\n",
      "Train Epoch: 20 [30000/41667 (72%)]\tLoss: 0.506263\n",
      "\n",
      "Train Epoch: 20 [40000/41667 (96%)]\tLoss: 0.612912\n",
      "\tAccuracy: 81.17%\n",
      "\n",
      "Train Epoch: 21 [0/41667 (0%)]\tLoss: 0.374792\n",
      "\n",
      "Train Epoch: 21 [10000/41667 (24%)]\tLoss: 0.374463\n",
      "\n",
      "Train Epoch: 21 [20000/41667 (48%)]\tLoss: 0.468358\n",
      "\n",
      "Train Epoch: 21 [30000/41667 (72%)]\tLoss: 0.514076\n",
      "\n",
      "Train Epoch: 21 [40000/41667 (96%)]\tLoss: 0.434119\n",
      "\tAccuracy: 81.93%\n",
      "\n",
      "Train Epoch: 22 [0/41667 (0%)]\tLoss: 0.476639\n",
      "\n",
      "Train Epoch: 22 [10000/41667 (24%)]\tLoss: 0.412210\n",
      "\n",
      "Train Epoch: 22 [20000/41667 (48%)]\tLoss: 0.499296\n",
      "\n",
      "Train Epoch: 22 [30000/41667 (72%)]\tLoss: 0.560992\n",
      "\n",
      "Train Epoch: 22 [40000/41667 (96%)]\tLoss: 0.681123\n",
      "\tAccuracy: 82.52%\n",
      "\n",
      "Train Epoch: 23 [0/41667 (0%)]\tLoss: 0.348450\n",
      "\n",
      "Train Epoch: 23 [10000/41667 (24%)]\tLoss: 0.475675\n",
      "\n",
      "Train Epoch: 23 [20000/41667 (48%)]\tLoss: 0.465429\n",
      "\n",
      "Train Epoch: 23 [30000/41667 (72%)]\tLoss: 0.541261\n",
      "\n",
      "Train Epoch: 23 [40000/41667 (96%)]\tLoss: 0.456426\n",
      "\tAccuracy: 83.45%\n",
      "\n",
      "Train Epoch: 24 [0/41667 (0%)]\tLoss: 0.332604\n",
      "\n",
      "Train Epoch: 24 [10000/41667 (24%)]\tLoss: 0.387206\n",
      "\n",
      "Train Epoch: 24 [20000/41667 (48%)]\tLoss: 0.392866\n",
      "\n",
      "Train Epoch: 24 [30000/41667 (72%)]\tLoss: 0.371624\n",
      "\n",
      "Train Epoch: 24 [40000/41667 (96%)]\tLoss: 0.549903\n",
      "\tAccuracy: 84.17%\n",
      "\n",
      "Train Epoch: 25 [0/41667 (0%)]\tLoss: 0.426610\n",
      "\n",
      "Train Epoch: 25 [10000/41667 (24%)]\tLoss: 0.320566\n",
      "\n",
      "Train Epoch: 25 [20000/41667 (48%)]\tLoss: 0.433611\n",
      "\n",
      "Train Epoch: 25 [30000/41667 (72%)]\tLoss: 0.348655\n",
      "\n",
      "Train Epoch: 25 [40000/41667 (96%)]\tLoss: 0.517715\n",
      "\tAccuracy: 85.12%\n",
      "Test set: Avg. loss: -683.8737, Accuracy: 4208/8333 (50.50%)\n",
      "Saving FC model: FC(\n",
      "  (layer_list): ModuleList(\n",
      "    (0): Linear(in_features=3072, out_features=200, bias=True)\n",
      "    (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Training FC model: FC(\n",
      "  (layer_list): ModuleList(\n",
      "    (0): Linear(in_features=3072, out_features=100, bias=True)\n",
      "    (1): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Train Epoch: 1 [0/41667 (0%)]\tLoss: 2.300700\n",
      "\n",
      "Train Epoch: 1 [10000/41667 (24%)]\tLoss: 1.903463\n",
      "\n",
      "Train Epoch: 1 [20000/41667 (48%)]\tLoss: 1.682575\n",
      "\n",
      "Train Epoch: 1 [30000/41667 (72%)]\tLoss: 1.467284\n",
      "\n",
      "Train Epoch: 1 [40000/41667 (96%)]\tLoss: 1.828100\n",
      "\tAccuracy: 34.81%\n",
      "\n",
      "Train Epoch: 2 [0/41667 (0%)]\tLoss: 1.473971\n",
      "\n",
      "Train Epoch: 2 [10000/41667 (24%)]\tLoss: 1.442508\n",
      "\n",
      "Train Epoch: 2 [20000/41667 (48%)]\tLoss: 1.505277\n",
      "\n",
      "Train Epoch: 2 [30000/41667 (72%)]\tLoss: 1.657016\n",
      "\n",
      "Train Epoch: 2 [40000/41667 (96%)]\tLoss: 1.579163\n",
      "\tAccuracy: 45.50%\n",
      "\n",
      "Train Epoch: 3 [0/41667 (0%)]\tLoss: 1.517640\n",
      "\n",
      "Train Epoch: 3 [10000/41667 (24%)]\tLoss: 1.556972\n",
      "\n",
      "Train Epoch: 3 [20000/41667 (48%)]\tLoss: 1.506494\n",
      "\n",
      "Train Epoch: 3 [30000/41667 (72%)]\tLoss: 1.347796\n",
      "\n",
      "Train Epoch: 3 [40000/41667 (96%)]\tLoss: 1.339304\n",
      "\tAccuracy: 49.84%\n",
      "\n",
      "Train Epoch: 4 [0/41667 (0%)]\tLoss: 1.290509\n",
      "\n",
      "Train Epoch: 4 [10000/41667 (24%)]\tLoss: 1.542574\n",
      "\n",
      "Train Epoch: 4 [20000/41667 (48%)]\tLoss: 1.481701\n",
      "\n",
      "Train Epoch: 4 [30000/41667 (72%)]\tLoss: 1.325093\n",
      "\n",
      "Train Epoch: 4 [40000/41667 (96%)]\tLoss: 1.320371\n",
      "\tAccuracy: 52.49%\n",
      "\n",
      "Train Epoch: 5 [0/41667 (0%)]\tLoss: 1.253733\n",
      "\n",
      "Train Epoch: 5 [10000/41667 (24%)]\tLoss: 1.305132\n",
      "\n",
      "Train Epoch: 5 [20000/41667 (48%)]\tLoss: 1.293051\n",
      "\n",
      "Train Epoch: 5 [30000/41667 (72%)]\tLoss: 1.267927\n",
      "\n",
      "Train Epoch: 5 [40000/41667 (96%)]\tLoss: 1.425830\n",
      "\tAccuracy: 54.81%\n",
      "\n",
      "Train Epoch: 6 [0/41667 (0%)]\tLoss: 1.209174\n",
      "\n",
      "Train Epoch: 6 [10000/41667 (24%)]\tLoss: 1.193366\n",
      "\n",
      "Train Epoch: 6 [20000/41667 (48%)]\tLoss: 1.226673\n",
      "\n",
      "Train Epoch: 6 [30000/41667 (72%)]\tLoss: 1.117075\n",
      "\n",
      "Train Epoch: 6 [40000/41667 (96%)]\tLoss: 1.096538\n",
      "\tAccuracy: 56.64%\n",
      "\n",
      "Train Epoch: 7 [0/41667 (0%)]\tLoss: 1.146939\n",
      "\n",
      "Train Epoch: 7 [10000/41667 (24%)]\tLoss: 0.983084\n",
      "\n",
      "Train Epoch: 7 [20000/41667 (48%)]\tLoss: 1.494672\n",
      "\n",
      "Train Epoch: 7 [30000/41667 (72%)]\tLoss: 1.189011\n",
      "\n",
      "Train Epoch: 7 [40000/41667 (96%)]\tLoss: 1.325009\n",
      "\tAccuracy: 58.08%\n",
      "\n",
      "Train Epoch: 8 [0/41667 (0%)]\tLoss: 1.167315\n",
      "\n",
      "Train Epoch: 8 [10000/41667 (24%)]\tLoss: 1.076185\n",
      "\n",
      "Train Epoch: 8 [20000/41667 (48%)]\tLoss: 1.146120\n",
      "\n",
      "Train Epoch: 8 [30000/41667 (72%)]\tLoss: 1.146454\n",
      "\n",
      "Train Epoch: 8 [40000/41667 (96%)]\tLoss: 1.141060\n",
      "\tAccuracy: 59.64%\n",
      "\n",
      "Train Epoch: 9 [0/41667 (0%)]\tLoss: 0.886752\n",
      "\n",
      "Train Epoch: 9 [10000/41667 (24%)]\tLoss: 1.059741\n",
      "\n",
      "Train Epoch: 9 [20000/41667 (48%)]\tLoss: 1.145726\n",
      "\n",
      "Train Epoch: 9 [30000/41667 (72%)]\tLoss: 1.263772\n",
      "\n",
      "Train Epoch: 9 [40000/41667 (96%)]\tLoss: 1.069414\n",
      "\tAccuracy: 60.90%\n",
      "\n",
      "Train Epoch: 10 [0/41667 (0%)]\tLoss: 1.237828\n",
      "\n",
      "Train Epoch: 10 [10000/41667 (24%)]\tLoss: 1.188494\n",
      "\n",
      "Train Epoch: 10 [20000/41667 (48%)]\tLoss: 1.030310\n",
      "\n",
      "Train Epoch: 10 [30000/41667 (72%)]\tLoss: 1.027991\n",
      "\n",
      "Train Epoch: 10 [40000/41667 (96%)]\tLoss: 1.160459\n",
      "\tAccuracy: 62.13%\n",
      "\n",
      "Train Epoch: 11 [0/41667 (0%)]\tLoss: 0.888406\n",
      "\n",
      "Train Epoch: 11 [10000/41667 (24%)]\tLoss: 1.188627\n",
      "\n",
      "Train Epoch: 11 [20000/41667 (48%)]\tLoss: 0.945900\n",
      "\n",
      "Train Epoch: 11 [30000/41667 (72%)]\tLoss: 1.032511\n",
      "\n",
      "Train Epoch: 11 [40000/41667 (96%)]\tLoss: 1.056802\n",
      "\tAccuracy: 63.23%\n",
      "\n",
      "Train Epoch: 12 [0/41667 (0%)]\tLoss: 1.030725\n",
      "\n",
      "Train Epoch: 12 [10000/41667 (24%)]\tLoss: 0.812174\n",
      "\n",
      "Train Epoch: 12 [20000/41667 (48%)]\tLoss: 1.033497\n",
      "\n",
      "Train Epoch: 12 [30000/41667 (72%)]\tLoss: 1.026919\n",
      "\n",
      "Train Epoch: 12 [40000/41667 (96%)]\tLoss: 1.128964\n",
      "\tAccuracy: 64.51%\n",
      "\n",
      "Train Epoch: 13 [0/41667 (0%)]\tLoss: 0.963474\n",
      "\n",
      "Train Epoch: 13 [10000/41667 (24%)]\tLoss: 0.886508\n",
      "\n",
      "Train Epoch: 13 [20000/41667 (48%)]\tLoss: 0.856288\n",
      "\n",
      "Train Epoch: 13 [30000/41667 (72%)]\tLoss: 1.030637\n",
      "\n",
      "Train Epoch: 13 [40000/41667 (96%)]\tLoss: 0.996760\n",
      "\tAccuracy: 65.43%\n",
      "\n",
      "Train Epoch: 14 [0/41667 (0%)]\tLoss: 0.878663\n",
      "\n",
      "Train Epoch: 14 [10000/41667 (24%)]\tLoss: 0.898652\n",
      "\n",
      "Train Epoch: 14 [20000/41667 (48%)]\tLoss: 0.879051\n",
      "\n",
      "Train Epoch: 14 [30000/41667 (72%)]\tLoss: 1.066024\n",
      "\n",
      "Train Epoch: 14 [40000/41667 (96%)]\tLoss: 0.950647\n",
      "\tAccuracy: 66.21%\n",
      "\n",
      "Train Epoch: 15 [0/41667 (0%)]\tLoss: 0.824452\n",
      "\n",
      "Train Epoch: 15 [10000/41667 (24%)]\tLoss: 0.985753\n",
      "\n",
      "Train Epoch: 15 [20000/41667 (48%)]\tLoss: 0.958554\n",
      "\n",
      "Train Epoch: 15 [30000/41667 (72%)]\tLoss: 1.073152\n",
      "\n",
      "Train Epoch: 15 [40000/41667 (96%)]\tLoss: 0.819109\n",
      "\tAccuracy: 67.45%\n",
      "\n",
      "Train Epoch: 16 [0/41667 (0%)]\tLoss: 0.850504\n",
      "\n",
      "Train Epoch: 16 [10000/41667 (24%)]\tLoss: 0.721355\n",
      "\n",
      "Train Epoch: 16 [20000/41667 (48%)]\tLoss: 0.827545\n",
      "\n",
      "Train Epoch: 16 [30000/41667 (72%)]\tLoss: 0.921351\n",
      "\n",
      "Train Epoch: 16 [40000/41667 (96%)]\tLoss: 0.747022\n",
      "\tAccuracy: 68.38%\n",
      "\n",
      "Train Epoch: 17 [0/41667 (0%)]\tLoss: 0.792463\n",
      "\n",
      "Train Epoch: 17 [10000/41667 (24%)]\tLoss: 0.779075\n",
      "\n",
      "Train Epoch: 17 [20000/41667 (48%)]\tLoss: 0.698661\n",
      "\n",
      "Train Epoch: 17 [30000/41667 (72%)]\tLoss: 0.991640\n",
      "\n",
      "Train Epoch: 17 [40000/41667 (96%)]\tLoss: 1.205994\n",
      "\tAccuracy: 69.14%\n",
      "\n",
      "Train Epoch: 18 [0/41667 (0%)]\tLoss: 0.648179\n",
      "\n",
      "Train Epoch: 18 [10000/41667 (24%)]\tLoss: 0.740859\n",
      "\n",
      "Train Epoch: 18 [20000/41667 (48%)]\tLoss: 0.911154\n",
      "\n",
      "Train Epoch: 18 [30000/41667 (72%)]\tLoss: 0.838318\n",
      "\n",
      "Train Epoch: 18 [40000/41667 (96%)]\tLoss: 0.892981\n",
      "\tAccuracy: 70.00%\n",
      "\n",
      "Train Epoch: 19 [0/41667 (0%)]\tLoss: 0.651243\n",
      "\n",
      "Train Epoch: 19 [10000/41667 (24%)]\tLoss: 0.800435\n",
      "\n",
      "Train Epoch: 19 [20000/41667 (48%)]\tLoss: 1.015794\n",
      "\n",
      "Train Epoch: 19 [30000/41667 (72%)]\tLoss: 0.819647\n",
      "\n",
      "Train Epoch: 19 [40000/41667 (96%)]\tLoss: 0.601783\n",
      "\tAccuracy: 70.65%\n",
      "\n",
      "Train Epoch: 20 [0/41667 (0%)]\tLoss: 0.764244\n",
      "\n",
      "Train Epoch: 20 [10000/41667 (24%)]\tLoss: 0.734440\n",
      "\n",
      "Train Epoch: 20 [20000/41667 (48%)]\tLoss: 0.712991\n",
      "\n",
      "Train Epoch: 20 [30000/41667 (72%)]\tLoss: 0.802619\n",
      "\n",
      "Train Epoch: 20 [40000/41667 (96%)]\tLoss: 0.892819\n",
      "\tAccuracy: 71.78%\n",
      "\n",
      "Train Epoch: 21 [0/41667 (0%)]\tLoss: 0.575232\n",
      "\n",
      "Train Epoch: 21 [10000/41667 (24%)]\tLoss: 0.722546\n",
      "\n",
      "Train Epoch: 21 [20000/41667 (48%)]\tLoss: 0.657490\n",
      "\n",
      "Train Epoch: 21 [30000/41667 (72%)]\tLoss: 0.816094\n",
      "\n",
      "Train Epoch: 21 [40000/41667 (96%)]\tLoss: 0.824480\n",
      "\tAccuracy: 72.32%\n",
      "\n",
      "Train Epoch: 22 [0/41667 (0%)]\tLoss: 0.624526\n",
      "\n",
      "Train Epoch: 22 [10000/41667 (24%)]\tLoss: 0.624231\n",
      "\n",
      "Train Epoch: 22 [20000/41667 (48%)]\tLoss: 0.793451\n",
      "\n",
      "Train Epoch: 22 [30000/41667 (72%)]\tLoss: 0.796777\n",
      "\n",
      "Train Epoch: 22 [40000/41667 (96%)]\tLoss: 0.679985\n",
      "\tAccuracy: 73.18%\n",
      "\n",
      "Train Epoch: 23 [0/41667 (0%)]\tLoss: 0.858697\n",
      "\n",
      "Train Epoch: 23 [10000/41667 (24%)]\tLoss: 0.644310\n",
      "\n",
      "Train Epoch: 23 [20000/41667 (48%)]\tLoss: 0.817583\n",
      "\n",
      "Train Epoch: 23 [30000/41667 (72%)]\tLoss: 0.773851\n",
      "\n",
      "Train Epoch: 23 [40000/41667 (96%)]\tLoss: 0.807417\n",
      "\tAccuracy: 73.61%\n",
      "\n",
      "Train Epoch: 24 [0/41667 (0%)]\tLoss: 0.607869\n",
      "\n",
      "Train Epoch: 24 [10000/41667 (24%)]\tLoss: 0.773407\n",
      "\n",
      "Train Epoch: 24 [20000/41667 (48%)]\tLoss: 0.754606\n",
      "\n",
      "Train Epoch: 24 [30000/41667 (72%)]\tLoss: 0.771578\n",
      "\n",
      "Train Epoch: 24 [40000/41667 (96%)]\tLoss: 0.677899\n",
      "\tAccuracy: 74.39%\n",
      "\n",
      "Train Epoch: 25 [0/41667 (0%)]\tLoss: 0.642363\n",
      "\n",
      "Train Epoch: 25 [10000/41667 (24%)]\tLoss: 0.581987\n",
      "\n",
      "Train Epoch: 25 [20000/41667 (48%)]\tLoss: 0.698799\n",
      "\n",
      "Train Epoch: 25 [30000/41667 (72%)]\tLoss: 0.479631\n",
      "\n",
      "Train Epoch: 25 [40000/41667 (96%)]\tLoss: 0.830207\n",
      "\tAccuracy: 74.81%\n",
      "Test set: Avg. loss: -471.1177, Accuracy: 4284/8333 (51.41%)\n",
      "Saving FC model: FC(\n",
      "  (layer_list): ModuleList(\n",
      "    (0): Linear(in_features=3072, out_features=100, bias=True)\n",
      "    (1): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Training FC model: FC(\n",
      "  (layer_list): ModuleList(\n",
      "    (0): Linear(in_features=3072, out_features=200, bias=True)\n",
      "    (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (3): Linear(in_features=200, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Train Epoch: 1 [0/41667 (0%)]\tLoss: 2.298718\n",
      "\n",
      "Train Epoch: 1 [10000/41667 (24%)]\tLoss: 1.886614\n",
      "\n",
      "Train Epoch: 1 [20000/41667 (48%)]\tLoss: 1.624769\n",
      "\n",
      "Train Epoch: 1 [30000/41667 (72%)]\tLoss: 1.771439\n",
      "\n",
      "Train Epoch: 1 [40000/41667 (96%)]\tLoss: 1.551099\n",
      "\tAccuracy: 36.33%\n",
      "\n",
      "Train Epoch: 2 [0/41667 (0%)]\tLoss: 1.593426\n",
      "\n",
      "Train Epoch: 2 [10000/41667 (24%)]\tLoss: 1.563219\n",
      "\n",
      "Train Epoch: 2 [20000/41667 (48%)]\tLoss: 1.341398\n",
      "\n",
      "Train Epoch: 2 [30000/41667 (72%)]\tLoss: 1.408082\n",
      "\n",
      "Train Epoch: 2 [40000/41667 (96%)]\tLoss: 1.556106\n",
      "\tAccuracy: 46.44%\n",
      "\n",
      "Train Epoch: 3 [0/41667 (0%)]\tLoss: 1.254421\n",
      "\n",
      "Train Epoch: 3 [10000/41667 (24%)]\tLoss: 1.338196\n",
      "\n",
      "Train Epoch: 3 [20000/41667 (48%)]\tLoss: 1.677181\n",
      "\n",
      "Train Epoch: 3 [30000/41667 (72%)]\tLoss: 1.181624\n",
      "\n",
      "Train Epoch: 3 [40000/41667 (96%)]\tLoss: 1.300673\n",
      "\tAccuracy: 50.95%\n",
      "\n",
      "Train Epoch: 4 [0/41667 (0%)]\tLoss: 1.461881\n",
      "\n",
      "Train Epoch: 4 [10000/41667 (24%)]\tLoss: 1.333996\n",
      "\n",
      "Train Epoch: 4 [20000/41667 (48%)]\tLoss: 1.468763\n",
      "\n",
      "Train Epoch: 4 [30000/41667 (72%)]\tLoss: 1.245073\n",
      "\n",
      "Train Epoch: 4 [40000/41667 (96%)]\tLoss: 1.662938\n",
      "\tAccuracy: 54.15%\n",
      "\n",
      "Train Epoch: 5 [0/41667 (0%)]\tLoss: 1.274581\n",
      "\n",
      "Train Epoch: 5 [10000/41667 (24%)]\tLoss: 1.123267\n",
      "\n",
      "Train Epoch: 5 [20000/41667 (48%)]\tLoss: 1.380722\n",
      "\n",
      "Train Epoch: 5 [30000/41667 (72%)]\tLoss: 1.313257\n",
      "\n",
      "Train Epoch: 5 [40000/41667 (96%)]\tLoss: 1.207160\n",
      "\tAccuracy: 56.84%\n",
      "\n",
      "Train Epoch: 6 [0/41667 (0%)]\tLoss: 1.153293\n",
      "\n",
      "Train Epoch: 6 [10000/41667 (24%)]\tLoss: 1.182585\n",
      "\n",
      "Train Epoch: 6 [20000/41667 (48%)]\tLoss: 1.230468\n",
      "\n",
      "Train Epoch: 6 [30000/41667 (72%)]\tLoss: 1.110684\n",
      "\n",
      "Train Epoch: 6 [40000/41667 (96%)]\tLoss: 0.975432\n",
      "\tAccuracy: 59.14%\n",
      "\n",
      "Train Epoch: 7 [0/41667 (0%)]\tLoss: 1.130472\n",
      "\n",
      "Train Epoch: 7 [10000/41667 (24%)]\tLoss: 1.007718\n",
      "\n",
      "Train Epoch: 7 [20000/41667 (48%)]\tLoss: 1.116926\n",
      "\n",
      "Train Epoch: 7 [30000/41667 (72%)]\tLoss: 1.174528\n",
      "\n",
      "Train Epoch: 7 [40000/41667 (96%)]\tLoss: 1.160389\n",
      "\tAccuracy: 61.17%\n",
      "\n",
      "Train Epoch: 8 [0/41667 (0%)]\tLoss: 1.154501\n",
      "\n",
      "Train Epoch: 8 [10000/41667 (24%)]\tLoss: 1.129516\n",
      "\n",
      "Train Epoch: 8 [20000/41667 (48%)]\tLoss: 0.891880\n",
      "\n",
      "Train Epoch: 8 [30000/41667 (72%)]\tLoss: 1.268224\n",
      "\n",
      "Train Epoch: 8 [40000/41667 (96%)]\tLoss: 1.205401\n",
      "\tAccuracy: 63.12%\n",
      "\n",
      "Train Epoch: 9 [0/41667 (0%)]\tLoss: 1.092104\n",
      "\n",
      "Train Epoch: 9 [10000/41667 (24%)]\tLoss: 0.973261\n",
      "\n",
      "Train Epoch: 9 [20000/41667 (48%)]\tLoss: 0.927875\n",
      "\n",
      "Train Epoch: 9 [30000/41667 (72%)]\tLoss: 1.088760\n",
      "\n",
      "Train Epoch: 9 [40000/41667 (96%)]\tLoss: 0.893887\n",
      "\tAccuracy: 65.17%\n",
      "\n",
      "Train Epoch: 10 [0/41667 (0%)]\tLoss: 0.853389\n",
      "\n",
      "Train Epoch: 10 [10000/41667 (24%)]\tLoss: 0.908255\n",
      "\n",
      "Train Epoch: 10 [20000/41667 (48%)]\tLoss: 1.200324\n",
      "\n",
      "Train Epoch: 10 [30000/41667 (72%)]\tLoss: 0.827601\n",
      "\n",
      "Train Epoch: 10 [40000/41667 (96%)]\tLoss: 1.126673\n",
      "\tAccuracy: 66.87%\n",
      "\n",
      "Train Epoch: 11 [0/41667 (0%)]\tLoss: 0.739776\n",
      "\n",
      "Train Epoch: 11 [10000/41667 (24%)]\tLoss: 0.960823\n",
      "\n",
      "Train Epoch: 11 [20000/41667 (48%)]\tLoss: 0.712282\n",
      "\n",
      "Train Epoch: 11 [30000/41667 (72%)]\tLoss: 0.819972\n",
      "\n",
      "Train Epoch: 11 [40000/41667 (96%)]\tLoss: 0.996423\n",
      "\tAccuracy: 68.60%\n",
      "\n",
      "Train Epoch: 12 [0/41667 (0%)]\tLoss: 0.689050\n",
      "\n",
      "Train Epoch: 12 [10000/41667 (24%)]\tLoss: 0.794467\n",
      "\n",
      "Train Epoch: 12 [20000/41667 (48%)]\tLoss: 0.852482\n",
      "\n",
      "Train Epoch: 12 [30000/41667 (72%)]\tLoss: 0.804223\n",
      "\n",
      "Train Epoch: 12 [40000/41667 (96%)]\tLoss: 0.786544\n",
      "\tAccuracy: 70.37%\n",
      "\n",
      "Train Epoch: 13 [0/41667 (0%)]\tLoss: 0.726460\n",
      "\n",
      "Train Epoch: 13 [10000/41667 (24%)]\tLoss: 0.656049\n",
      "\n",
      "Train Epoch: 13 [20000/41667 (48%)]\tLoss: 0.872464\n",
      "\n",
      "Train Epoch: 13 [30000/41667 (72%)]\tLoss: 0.746704\n",
      "\n",
      "Train Epoch: 13 [40000/41667 (96%)]\tLoss: 0.758593\n",
      "\tAccuracy: 71.92%\n",
      "\n",
      "Train Epoch: 14 [0/41667 (0%)]\tLoss: 0.708139\n",
      "\n",
      "Train Epoch: 14 [10000/41667 (24%)]\tLoss: 0.735240\n",
      "\n",
      "Train Epoch: 14 [20000/41667 (48%)]\tLoss: 0.706895\n",
      "\n",
      "Train Epoch: 14 [30000/41667 (72%)]\tLoss: 0.759238\n",
      "\n",
      "Train Epoch: 14 [40000/41667 (96%)]\tLoss: 0.847077\n",
      "\tAccuracy: 73.78%\n",
      "\n",
      "Train Epoch: 15 [0/41667 (0%)]\tLoss: 0.630607\n",
      "\n",
      "Train Epoch: 15 [10000/41667 (24%)]\tLoss: 0.544157\n",
      "\n",
      "Train Epoch: 15 [20000/41667 (48%)]\tLoss: 0.713172\n",
      "\n",
      "Train Epoch: 15 [30000/41667 (72%)]\tLoss: 0.783485\n",
      "\n",
      "Train Epoch: 15 [40000/41667 (96%)]\tLoss: 0.769168\n",
      "\tAccuracy: 74.98%\n",
      "\n",
      "Train Epoch: 16 [0/41667 (0%)]\tLoss: 0.524665\n",
      "\n",
      "Train Epoch: 16 [10000/41667 (24%)]\tLoss: 0.669377\n",
      "\n",
      "Train Epoch: 16 [20000/41667 (48%)]\tLoss: 0.630708\n",
      "\n",
      "Train Epoch: 16 [30000/41667 (72%)]\tLoss: 0.693562\n",
      "\n",
      "Train Epoch: 16 [40000/41667 (96%)]\tLoss: 0.881102\n",
      "\tAccuracy: 76.56%\n",
      "\n",
      "Train Epoch: 17 [0/41667 (0%)]\tLoss: 0.496407\n",
      "\n",
      "Train Epoch: 17 [10000/41667 (24%)]\tLoss: 0.654438\n",
      "\n",
      "Train Epoch: 17 [20000/41667 (48%)]\tLoss: 0.581950\n",
      "\n",
      "Train Epoch: 17 [30000/41667 (72%)]\tLoss: 0.699664\n",
      "\n",
      "Train Epoch: 17 [40000/41667 (96%)]\tLoss: 0.885745\n",
      "\tAccuracy: 77.99%\n",
      "\n",
      "Train Epoch: 18 [0/41667 (0%)]\tLoss: 0.405816\n",
      "\n",
      "Train Epoch: 18 [10000/41667 (24%)]\tLoss: 0.548245\n",
      "\n",
      "Train Epoch: 18 [20000/41667 (48%)]\tLoss: 0.586743\n",
      "\n",
      "Train Epoch: 18 [30000/41667 (72%)]\tLoss: 0.543559\n",
      "\n",
      "Train Epoch: 18 [40000/41667 (96%)]\tLoss: 0.671219\n",
      "\tAccuracy: 79.38%\n",
      "\n",
      "Train Epoch: 19 [0/41667 (0%)]\tLoss: 0.538000\n",
      "\n",
      "Train Epoch: 19 [10000/41667 (24%)]\tLoss: 0.500599\n",
      "\n",
      "Train Epoch: 19 [20000/41667 (48%)]\tLoss: 0.544982\n",
      "\n",
      "Train Epoch: 19 [30000/41667 (72%)]\tLoss: 0.683975\n",
      "\n",
      "Train Epoch: 19 [40000/41667 (96%)]\tLoss: 0.601918\n",
      "\tAccuracy: 80.60%\n",
      "\n",
      "Train Epoch: 20 [0/41667 (0%)]\tLoss: 0.465306\n",
      "\n",
      "Train Epoch: 20 [10000/41667 (24%)]\tLoss: 0.581057\n",
      "\n",
      "Train Epoch: 20 [20000/41667 (48%)]\tLoss: 0.593070\n",
      "\n",
      "Train Epoch: 20 [30000/41667 (72%)]\tLoss: 0.510882\n",
      "\n",
      "Train Epoch: 20 [40000/41667 (96%)]\tLoss: 0.457224\n",
      "\tAccuracy: 81.74%\n",
      "\n",
      "Train Epoch: 21 [0/41667 (0%)]\tLoss: 0.438651\n",
      "\n",
      "Train Epoch: 21 [10000/41667 (24%)]\tLoss: 0.370328\n",
      "\n",
      "Train Epoch: 21 [20000/41667 (48%)]\tLoss: 0.472689\n",
      "\n",
      "Train Epoch: 21 [30000/41667 (72%)]\tLoss: 0.552508\n",
      "\n",
      "Train Epoch: 21 [40000/41667 (96%)]\tLoss: 0.464147\n",
      "\tAccuracy: 82.61%\n",
      "\n",
      "Train Epoch: 22 [0/41667 (0%)]\tLoss: 0.475157\n",
      "\n",
      "Train Epoch: 22 [10000/41667 (24%)]\tLoss: 0.444179\n",
      "\n",
      "Train Epoch: 22 [20000/41667 (48%)]\tLoss: 0.481147\n",
      "\n",
      "Train Epoch: 22 [30000/41667 (72%)]\tLoss: 0.473287\n",
      "\n",
      "Train Epoch: 22 [40000/41667 (96%)]\tLoss: 0.492236\n",
      "\tAccuracy: 83.72%\n",
      "\n",
      "Train Epoch: 23 [0/41667 (0%)]\tLoss: 0.359477\n",
      "\n",
      "Train Epoch: 23 [10000/41667 (24%)]\tLoss: 0.385827\n",
      "\n",
      "Train Epoch: 23 [20000/41667 (48%)]\tLoss: 0.486597\n",
      "\n",
      "Train Epoch: 23 [30000/41667 (72%)]\tLoss: 0.469628\n",
      "\n",
      "Train Epoch: 23 [40000/41667 (96%)]\tLoss: 0.555409\n",
      "\tAccuracy: 85.05%\n",
      "\n",
      "Train Epoch: 24 [0/41667 (0%)]\tLoss: 0.251680\n",
      "\n",
      "Train Epoch: 24 [10000/41667 (24%)]\tLoss: 0.647308\n",
      "\n",
      "Train Epoch: 24 [20000/41667 (48%)]\tLoss: 0.312516\n",
      "\n",
      "Train Epoch: 24 [30000/41667 (72%)]\tLoss: 0.625512\n",
      "\n",
      "Train Epoch: 24 [40000/41667 (96%)]\tLoss: 0.522465\n",
      "\tAccuracy: 85.31%\n",
      "\n",
      "Train Epoch: 25 [0/41667 (0%)]\tLoss: 0.397163\n",
      "\n",
      "Train Epoch: 25 [10000/41667 (24%)]\tLoss: 0.354190\n",
      "\n",
      "Train Epoch: 25 [20000/41667 (48%)]\tLoss: 0.366974\n",
      "\n",
      "Train Epoch: 25 [30000/41667 (72%)]\tLoss: 0.287230\n",
      "\n",
      "Train Epoch: 25 [40000/41667 (96%)]\tLoss: 0.391791\n",
      "\tAccuracy: 86.46%\n",
      "Test set: Avg. loss: -677.5005, Accuracy: 4283/8333 (51.40%)\n",
      "Saving FC model: FC(\n",
      "  (layer_list): ModuleList(\n",
      "    (0): Linear(in_features=3072, out_features=200, bias=True)\n",
      "    (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (3): Linear(in_features=200, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Training FC model: FC(\n",
      "  (layer_list): ModuleList(\n",
      "    (0): Linear(in_features=3072, out_features=100, bias=True)\n",
      "    (1): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Train Epoch: 1 [0/41667 (0%)]\tLoss: 2.308123\n",
      "\n",
      "Train Epoch: 1 [10000/41667 (24%)]\tLoss: 2.204394\n",
      "\n",
      "Train Epoch: 1 [20000/41667 (48%)]\tLoss: 1.931231\n",
      "\n",
      "Train Epoch: 1 [30000/41667 (72%)]\tLoss: 1.808764\n",
      "\n",
      "Train Epoch: 1 [40000/41667 (96%)]\tLoss: 1.454644\n",
      "\tAccuracy: 28.59%\n",
      "\n",
      "Train Epoch: 2 [0/41667 (0%)]\tLoss: 1.579522\n",
      "\n",
      "Train Epoch: 2 [10000/41667 (24%)]\tLoss: 1.643806\n",
      "\n",
      "Train Epoch: 2 [20000/41667 (48%)]\tLoss: 1.626049\n",
      "\n",
      "Train Epoch: 2 [30000/41667 (72%)]\tLoss: 1.599388\n",
      "\n",
      "Train Epoch: 2 [40000/41667 (96%)]\tLoss: 1.433695\n",
      "\tAccuracy: 43.68%\n",
      "\n",
      "Train Epoch: 3 [0/41667 (0%)]\tLoss: 1.558772\n",
      "\n",
      "Train Epoch: 3 [10000/41667 (24%)]\tLoss: 1.321901\n",
      "\n",
      "Train Epoch: 3 [20000/41667 (48%)]\tLoss: 1.371002\n",
      "\n",
      "Train Epoch: 3 [30000/41667 (72%)]\tLoss: 1.553250\n",
      "\n",
      "Train Epoch: 3 [40000/41667 (96%)]\tLoss: 1.313758\n",
      "\tAccuracy: 47.79%\n",
      "\n",
      "Train Epoch: 4 [0/41667 (0%)]\tLoss: 1.250707\n",
      "\n",
      "Train Epoch: 4 [10000/41667 (24%)]\tLoss: 1.416595\n",
      "\n",
      "Train Epoch: 4 [20000/41667 (48%)]\tLoss: 1.292130\n",
      "\n",
      "Train Epoch: 4 [30000/41667 (72%)]\tLoss: 1.394674\n",
      "\n",
      "Train Epoch: 4 [40000/41667 (96%)]\tLoss: 1.508531\n",
      "\tAccuracy: 51.14%\n",
      "\n",
      "Train Epoch: 5 [0/41667 (0%)]\tLoss: 1.267751\n",
      "\n",
      "Train Epoch: 5 [10000/41667 (24%)]\tLoss: 1.363746\n",
      "\n",
      "Train Epoch: 5 [20000/41667 (48%)]\tLoss: 1.284649\n",
      "\n",
      "Train Epoch: 5 [30000/41667 (72%)]\tLoss: 1.171561\n",
      "\n",
      "Train Epoch: 5 [40000/41667 (96%)]\tLoss: 1.438981\n",
      "\tAccuracy: 53.26%\n",
      "\n",
      "Train Epoch: 6 [0/41667 (0%)]\tLoss: 1.099924\n",
      "\n",
      "Train Epoch: 6 [10000/41667 (24%)]\tLoss: 1.407382\n",
      "\n",
      "Train Epoch: 6 [20000/41667 (48%)]\tLoss: 1.152726\n",
      "\n",
      "Train Epoch: 6 [30000/41667 (72%)]\tLoss: 1.232648\n",
      "\n",
      "Train Epoch: 6 [40000/41667 (96%)]\tLoss: 1.184785\n",
      "\tAccuracy: 55.74%\n",
      "\n",
      "Train Epoch: 7 [0/41667 (0%)]\tLoss: 1.256022\n",
      "\n",
      "Train Epoch: 7 [10000/41667 (24%)]\tLoss: 1.089730\n",
      "\n",
      "Train Epoch: 7 [20000/41667 (48%)]\tLoss: 1.188171\n",
      "\n",
      "Train Epoch: 7 [30000/41667 (72%)]\tLoss: 1.149244\n",
      "\n",
      "Train Epoch: 7 [40000/41667 (96%)]\tLoss: 1.182260\n",
      "\tAccuracy: 57.43%\n",
      "\n",
      "Train Epoch: 8 [0/41667 (0%)]\tLoss: 1.156569\n",
      "\n",
      "Train Epoch: 8 [10000/41667 (24%)]\tLoss: 1.190857\n",
      "\n",
      "Train Epoch: 8 [20000/41667 (48%)]\tLoss: 1.102676\n",
      "\n",
      "Train Epoch: 8 [30000/41667 (72%)]\tLoss: 1.020990\n",
      "\n",
      "Train Epoch: 8 [40000/41667 (96%)]\tLoss: 1.344949\n",
      "\tAccuracy: 58.91%\n",
      "\n",
      "Train Epoch: 9 [0/41667 (0%)]\tLoss: 1.107220\n",
      "\n",
      "Train Epoch: 9 [10000/41667 (24%)]\tLoss: 1.136606\n",
      "\n",
      "Train Epoch: 9 [20000/41667 (48%)]\tLoss: 1.153559\n",
      "\n",
      "Train Epoch: 9 [30000/41667 (72%)]\tLoss: 1.360842\n",
      "\n",
      "Train Epoch: 9 [40000/41667 (96%)]\tLoss: 1.297839\n",
      "\tAccuracy: 60.05%\n",
      "\n",
      "Train Epoch: 10 [0/41667 (0%)]\tLoss: 1.036650\n",
      "\n",
      "Train Epoch: 10 [10000/41667 (24%)]\tLoss: 0.948619\n",
      "\n",
      "Train Epoch: 10 [20000/41667 (48%)]\tLoss: 0.975149\n",
      "\n",
      "Train Epoch: 10 [30000/41667 (72%)]\tLoss: 1.275082\n",
      "\n",
      "Train Epoch: 10 [40000/41667 (96%)]\tLoss: 1.180084\n",
      "\tAccuracy: 62.04%\n",
      "\n",
      "Train Epoch: 11 [0/41667 (0%)]\tLoss: 1.059080\n",
      "\n",
      "Train Epoch: 11 [10000/41667 (24%)]\tLoss: 0.887908\n",
      "\n",
      "Train Epoch: 11 [20000/41667 (48%)]\tLoss: 1.014550\n",
      "\n",
      "Train Epoch: 11 [30000/41667 (72%)]\tLoss: 0.991003\n",
      "\n",
      "Train Epoch: 11 [40000/41667 (96%)]\tLoss: 1.221397\n",
      "\tAccuracy: 62.74%\n",
      "\n",
      "Train Epoch: 12 [0/41667 (0%)]\tLoss: 0.931545\n",
      "\n",
      "Train Epoch: 12 [10000/41667 (24%)]\tLoss: 1.033383\n",
      "\n",
      "Train Epoch: 12 [20000/41667 (48%)]\tLoss: 1.012226\n",
      "\n",
      "Train Epoch: 12 [30000/41667 (72%)]\tLoss: 1.092138\n",
      "\n",
      "Train Epoch: 12 [40000/41667 (96%)]\tLoss: 0.964915\n",
      "\tAccuracy: 64.12%\n",
      "\n",
      "Train Epoch: 13 [0/41667 (0%)]\tLoss: 0.850334\n",
      "\n",
      "Train Epoch: 13 [10000/41667 (24%)]\tLoss: 0.990811\n",
      "\n",
      "Train Epoch: 13 [20000/41667 (48%)]\tLoss: 1.037149\n",
      "\n",
      "Train Epoch: 13 [30000/41667 (72%)]\tLoss: 1.124451\n",
      "\n",
      "Train Epoch: 13 [40000/41667 (96%)]\tLoss: 1.262043\n",
      "\tAccuracy: 65.18%\n",
      "\n",
      "Train Epoch: 14 [0/41667 (0%)]\tLoss: 0.995339\n",
      "\n",
      "Train Epoch: 14 [10000/41667 (24%)]\tLoss: 1.016914\n",
      "\n",
      "Train Epoch: 14 [20000/41667 (48%)]\tLoss: 1.033608\n",
      "\n",
      "Train Epoch: 14 [30000/41667 (72%)]\tLoss: 1.147299\n",
      "\n",
      "Train Epoch: 14 [40000/41667 (96%)]\tLoss: 1.083715\n",
      "\tAccuracy: 66.03%\n",
      "\n",
      "Train Epoch: 15 [0/41667 (0%)]\tLoss: 0.868143\n",
      "\n",
      "Train Epoch: 15 [10000/41667 (24%)]\tLoss: 0.726334\n",
      "\n",
      "Train Epoch: 15 [20000/41667 (48%)]\tLoss: 0.908810\n",
      "\n",
      "Train Epoch: 15 [30000/41667 (72%)]\tLoss: 1.013984\n",
      "\n",
      "Train Epoch: 15 [40000/41667 (96%)]\tLoss: 1.006316\n",
      "\tAccuracy: 67.07%\n",
      "\n",
      "Train Epoch: 16 [0/41667 (0%)]\tLoss: 1.122145\n",
      "\n",
      "Train Epoch: 16 [10000/41667 (24%)]\tLoss: 0.827461\n",
      "\n",
      "Train Epoch: 16 [20000/41667 (48%)]\tLoss: 0.958709\n",
      "\n",
      "Train Epoch: 16 [30000/41667 (72%)]\tLoss: 1.004319\n",
      "\n",
      "Train Epoch: 16 [40000/41667 (96%)]\tLoss: 0.928377\n",
      "\tAccuracy: 67.89%\n",
      "\n",
      "Train Epoch: 17 [0/41667 (0%)]\tLoss: 0.657287\n",
      "\n",
      "Train Epoch: 17 [10000/41667 (24%)]\tLoss: 0.867692\n",
      "\n",
      "Train Epoch: 17 [20000/41667 (48%)]\tLoss: 1.025075\n",
      "\n",
      "Train Epoch: 17 [30000/41667 (72%)]\tLoss: 0.970294\n",
      "\n",
      "Train Epoch: 17 [40000/41667 (96%)]\tLoss: 0.781425\n",
      "\tAccuracy: 68.78%\n",
      "\n",
      "Train Epoch: 18 [0/41667 (0%)]\tLoss: 0.855461\n",
      "\n",
      "Train Epoch: 18 [10000/41667 (24%)]\tLoss: 0.869042\n",
      "\n",
      "Train Epoch: 18 [20000/41667 (48%)]\tLoss: 0.652464\n",
      "\n",
      "Train Epoch: 18 [30000/41667 (72%)]\tLoss: 0.868262\n",
      "\n",
      "Train Epoch: 18 [40000/41667 (96%)]\tLoss: 0.957461\n",
      "\tAccuracy: 69.74%\n",
      "\n",
      "Train Epoch: 19 [0/41667 (0%)]\tLoss: 0.748595\n",
      "\n",
      "Train Epoch: 19 [10000/41667 (24%)]\tLoss: 0.639961\n",
      "\n",
      "Train Epoch: 19 [20000/41667 (48%)]\tLoss: 0.777050\n",
      "\n",
      "Train Epoch: 19 [30000/41667 (72%)]\tLoss: 0.927485\n",
      "\n",
      "Train Epoch: 19 [40000/41667 (96%)]\tLoss: 0.765014\n",
      "\tAccuracy: 70.18%\n",
      "\n",
      "Train Epoch: 20 [0/41667 (0%)]\tLoss: 0.742412\n",
      "\n",
      "Train Epoch: 20 [10000/41667 (24%)]\tLoss: 0.743229\n",
      "\n",
      "Train Epoch: 20 [20000/41667 (48%)]\tLoss: 0.816322\n",
      "\n",
      "Train Epoch: 20 [30000/41667 (72%)]\tLoss: 0.857124\n",
      "\n",
      "Train Epoch: 20 [40000/41667 (96%)]\tLoss: 0.963859\n",
      "\tAccuracy: 71.36%\n",
      "\n",
      "Train Epoch: 21 [0/41667 (0%)]\tLoss: 0.634160\n",
      "\n",
      "Train Epoch: 21 [10000/41667 (24%)]\tLoss: 0.811594\n",
      "\n",
      "Train Epoch: 21 [20000/41667 (48%)]\tLoss: 0.811516\n",
      "\n",
      "Train Epoch: 21 [30000/41667 (72%)]\tLoss: 0.760114\n",
      "\n",
      "Train Epoch: 21 [40000/41667 (96%)]\tLoss: 0.828840\n",
      "\tAccuracy: 72.05%\n",
      "\n",
      "Train Epoch: 22 [0/41667 (0%)]\tLoss: 0.779809\n",
      "\n",
      "Train Epoch: 22 [10000/41667 (24%)]\tLoss: 0.903791\n",
      "\n",
      "Train Epoch: 22 [20000/41667 (48%)]\tLoss: 0.692576\n",
      "\n",
      "Train Epoch: 22 [30000/41667 (72%)]\tLoss: 0.594404\n",
      "\n",
      "Train Epoch: 22 [40000/41667 (96%)]\tLoss: 0.672869\n",
      "\tAccuracy: 72.65%\n",
      "\n",
      "Train Epoch: 23 [0/41667 (0%)]\tLoss: 0.929382\n",
      "\n",
      "Train Epoch: 23 [10000/41667 (24%)]\tLoss: 0.729942\n",
      "\n",
      "Train Epoch: 23 [20000/41667 (48%)]\tLoss: 0.820422\n",
      "\n",
      "Train Epoch: 23 [30000/41667 (72%)]\tLoss: 0.636048\n",
      "\n",
      "Train Epoch: 23 [40000/41667 (96%)]\tLoss: 0.816379\n",
      "\tAccuracy: 73.26%\n",
      "\n",
      "Train Epoch: 24 [0/41667 (0%)]\tLoss: 0.675539\n",
      "\n",
      "Train Epoch: 24 [10000/41667 (24%)]\tLoss: 0.539026\n",
      "\n",
      "Train Epoch: 24 [20000/41667 (48%)]\tLoss: 0.685023\n",
      "\n",
      "Train Epoch: 24 [30000/41667 (72%)]\tLoss: 0.558775\n",
      "\n",
      "Train Epoch: 24 [40000/41667 (96%)]\tLoss: 0.660321\n",
      "\tAccuracy: 74.03%\n",
      "\n",
      "Train Epoch: 25 [0/41667 (0%)]\tLoss: 0.629029\n",
      "\n",
      "Train Epoch: 25 [10000/41667 (24%)]\tLoss: 0.793222\n",
      "\n",
      "Train Epoch: 25 [20000/41667 (48%)]\tLoss: 0.652756\n",
      "\n",
      "Train Epoch: 25 [30000/41667 (72%)]\tLoss: 0.657977\n",
      "\n",
      "Train Epoch: 25 [40000/41667 (96%)]\tLoss: 0.763763\n",
      "\tAccuracy: 74.29%\n",
      "Test set: Avg. loss: -433.8671, Accuracy: 4189/8333 (50.27%)\n",
      "Saving FC model: FC(\n",
      "  (layer_list): ModuleList(\n",
      "    (0): Linear(in_features=3072, out_features=100, bias=True)\n",
      "    (1): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Training FC model: FC(\n",
      "  (layer_list): ModuleList(\n",
      "    (0): Linear(in_features=3072, out_features=200, bias=True)\n",
      "    (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (3): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (4): Linear(in_features=200, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Train Epoch: 1 [0/41667 (0%)]\tLoss: 2.311024\n",
      "\n",
      "Train Epoch: 1 [10000/41667 (24%)]\tLoss: 2.131918\n",
      "\n",
      "Train Epoch: 1 [20000/41667 (48%)]\tLoss: 1.870263\n",
      "\n",
      "Train Epoch: 1 [30000/41667 (72%)]\tLoss: 1.798856\n",
      "\n",
      "Train Epoch: 1 [40000/41667 (96%)]\tLoss: 1.682335\n",
      "\tAccuracy: 31.03%\n",
      "\n",
      "Train Epoch: 2 [0/41667 (0%)]\tLoss: 1.573207\n",
      "\n",
      "Train Epoch: 2 [10000/41667 (24%)]\tLoss: 1.601491\n",
      "\n",
      "Train Epoch: 2 [20000/41667 (48%)]\tLoss: 1.583365\n",
      "\n",
      "Train Epoch: 2 [30000/41667 (72%)]\tLoss: 1.567290\n",
      "\n",
      "Train Epoch: 2 [40000/41667 (96%)]\tLoss: 1.468095\n",
      "\tAccuracy: 44.10%\n",
      "\n",
      "Train Epoch: 3 [0/41667 (0%)]\tLoss: 1.495541\n",
      "\n",
      "Train Epoch: 3 [10000/41667 (24%)]\tLoss: 1.261339\n",
      "\n",
      "Train Epoch: 3 [20000/41667 (48%)]\tLoss: 1.473520\n",
      "\n",
      "Train Epoch: 3 [30000/41667 (72%)]\tLoss: 1.556463\n",
      "\n",
      "Train Epoch: 3 [40000/41667 (96%)]\tLoss: 1.389762\n",
      "\tAccuracy: 49.59%\n",
      "\n",
      "Train Epoch: 4 [0/41667 (0%)]\tLoss: 1.251626\n",
      "\n",
      "Train Epoch: 4 [10000/41667 (24%)]\tLoss: 1.109035\n",
      "\n",
      "Train Epoch: 4 [20000/41667 (48%)]\tLoss: 1.360055\n",
      "\n",
      "Train Epoch: 4 [30000/41667 (72%)]\tLoss: 1.330323\n",
      "\n",
      "Train Epoch: 4 [40000/41667 (96%)]\tLoss: 1.479703\n",
      "\tAccuracy: 52.71%\n",
      "\n",
      "Train Epoch: 5 [0/41667 (0%)]\tLoss: 1.305768\n",
      "\n",
      "Train Epoch: 5 [10000/41667 (24%)]\tLoss: 1.176147\n",
      "\n",
      "Train Epoch: 5 [20000/41667 (48%)]\tLoss: 1.050063\n",
      "\n",
      "Train Epoch: 5 [30000/41667 (72%)]\tLoss: 1.247579\n",
      "\n",
      "Train Epoch: 5 [40000/41667 (96%)]\tLoss: 1.326605\n",
      "\tAccuracy: 55.79%\n",
      "\n",
      "Train Epoch: 6 [0/41667 (0%)]\tLoss: 1.310786\n",
      "\n",
      "Train Epoch: 6 [10000/41667 (24%)]\tLoss: 1.257177\n",
      "\n",
      "Train Epoch: 6 [20000/41667 (48%)]\tLoss: 1.188435\n",
      "\n",
      "Train Epoch: 6 [30000/41667 (72%)]\tLoss: 1.111789\n",
      "\n",
      "Train Epoch: 6 [40000/41667 (96%)]\tLoss: 1.229948\n",
      "\tAccuracy: 57.87%\n",
      "\n",
      "Train Epoch: 7 [0/41667 (0%)]\tLoss: 1.117839\n",
      "\n",
      "Train Epoch: 7 [10000/41667 (24%)]\tLoss: 1.174895\n",
      "\n",
      "Train Epoch: 7 [20000/41667 (48%)]\tLoss: 1.108728\n",
      "\n",
      "Train Epoch: 7 [30000/41667 (72%)]\tLoss: 1.056273\n",
      "\n",
      "Train Epoch: 7 [40000/41667 (96%)]\tLoss: 1.119914\n",
      "\tAccuracy: 60.17%\n",
      "\n",
      "Train Epoch: 8 [0/41667 (0%)]\tLoss: 1.025876\n",
      "\n",
      "Train Epoch: 8 [10000/41667 (24%)]\tLoss: 0.915130\n",
      "\n",
      "Train Epoch: 8 [20000/41667 (48%)]\tLoss: 1.185566\n",
      "\n",
      "Train Epoch: 8 [30000/41667 (72%)]\tLoss: 1.187942\n",
      "\n",
      "Train Epoch: 8 [40000/41667 (96%)]\tLoss: 1.165442\n",
      "\tAccuracy: 61.96%\n",
      "\n",
      "Train Epoch: 9 [0/41667 (0%)]\tLoss: 1.001939\n",
      "\n",
      "Train Epoch: 9 [10000/41667 (24%)]\tLoss: 1.005370\n",
      "\n",
      "Train Epoch: 9 [20000/41667 (48%)]\tLoss: 0.924307\n",
      "\n",
      "Train Epoch: 9 [30000/41667 (72%)]\tLoss: 0.989401\n",
      "\n",
      "Train Epoch: 9 [40000/41667 (96%)]\tLoss: 1.052840\n",
      "\tAccuracy: 63.99%\n",
      "\n",
      "Train Epoch: 10 [0/41667 (0%)]\tLoss: 1.045274\n",
      "\n",
      "Train Epoch: 10 [10000/41667 (24%)]\tLoss: 1.006471\n",
      "\n",
      "Train Epoch: 10 [20000/41667 (48%)]\tLoss: 0.861614\n",
      "\n",
      "Train Epoch: 10 [30000/41667 (72%)]\tLoss: 1.032135\n",
      "\n",
      "Train Epoch: 10 [40000/41667 (96%)]\tLoss: 1.365208\n",
      "\tAccuracy: 65.71%\n",
      "\n",
      "Train Epoch: 11 [0/41667 (0%)]\tLoss: 0.852204\n",
      "\n",
      "Train Epoch: 11 [10000/41667 (24%)]\tLoss: 0.827881\n",
      "\n",
      "Train Epoch: 11 [20000/41667 (48%)]\tLoss: 0.996204\n",
      "\n",
      "Train Epoch: 11 [30000/41667 (72%)]\tLoss: 0.916451\n",
      "\n",
      "Train Epoch: 11 [40000/41667 (96%)]\tLoss: 0.916130\n",
      "\tAccuracy: 67.07%\n",
      "\n",
      "Train Epoch: 12 [0/41667 (0%)]\tLoss: 0.760233\n",
      "\n",
      "Train Epoch: 12 [10000/41667 (24%)]\tLoss: 0.839414\n",
      "\n",
      "Train Epoch: 12 [20000/41667 (48%)]\tLoss: 0.918685\n",
      "\n",
      "Train Epoch: 12 [30000/41667 (72%)]\tLoss: 0.875926\n",
      "\n",
      "Train Epoch: 12 [40000/41667 (96%)]\tLoss: 0.754724\n",
      "\tAccuracy: 68.98%\n",
      "\n",
      "Train Epoch: 13 [0/41667 (0%)]\tLoss: 0.829274\n",
      "\n",
      "Train Epoch: 13 [10000/41667 (24%)]\tLoss: 0.827624\n",
      "\n",
      "Train Epoch: 13 [20000/41667 (48%)]\tLoss: 0.696439\n",
      "\n",
      "Train Epoch: 13 [30000/41667 (72%)]\tLoss: 0.930323\n",
      "\n",
      "Train Epoch: 13 [40000/41667 (96%)]\tLoss: 0.673269\n",
      "\tAccuracy: 70.77%\n",
      "\n",
      "Train Epoch: 14 [0/41667 (0%)]\tLoss: 0.685990\n",
      "\n",
      "Train Epoch: 14 [10000/41667 (24%)]\tLoss: 0.738445\n",
      "\n",
      "Train Epoch: 14 [20000/41667 (48%)]\tLoss: 0.582130\n",
      "\n",
      "Train Epoch: 14 [30000/41667 (72%)]\tLoss: 0.715744\n",
      "\n",
      "Train Epoch: 14 [40000/41667 (96%)]\tLoss: 0.784673\n",
      "\tAccuracy: 72.45%\n",
      "\n",
      "Train Epoch: 15 [0/41667 (0%)]\tLoss: 0.646183\n",
      "\n",
      "Train Epoch: 15 [10000/41667 (24%)]\tLoss: 0.729540\n",
      "\n",
      "Train Epoch: 15 [20000/41667 (48%)]\tLoss: 0.502856\n",
      "\n",
      "Train Epoch: 15 [30000/41667 (72%)]\tLoss: 0.712187\n",
      "\n",
      "Train Epoch: 15 [40000/41667 (96%)]\tLoss: 0.652634\n",
      "\tAccuracy: 73.85%\n",
      "\n",
      "Train Epoch: 16 [0/41667 (0%)]\tLoss: 0.801614\n",
      "\n",
      "Train Epoch: 16 [10000/41667 (24%)]\tLoss: 0.505712\n",
      "\n",
      "Train Epoch: 16 [20000/41667 (48%)]\tLoss: 0.593535\n",
      "\n",
      "Train Epoch: 16 [30000/41667 (72%)]\tLoss: 0.782510\n",
      "\n",
      "Train Epoch: 16 [40000/41667 (96%)]\tLoss: 0.762069\n",
      "\tAccuracy: 75.05%\n",
      "\n",
      "Train Epoch: 17 [0/41667 (0%)]\tLoss: 0.724795\n",
      "\n",
      "Train Epoch: 17 [10000/41667 (24%)]\tLoss: 0.711341\n",
      "\n",
      "Train Epoch: 17 [20000/41667 (48%)]\tLoss: 0.584128\n",
      "\n",
      "Train Epoch: 17 [30000/41667 (72%)]\tLoss: 0.722208\n",
      "\n",
      "Train Epoch: 17 [40000/41667 (96%)]\tLoss: 0.619441\n",
      "\tAccuracy: 76.57%\n",
      "\n",
      "Train Epoch: 18 [0/41667 (0%)]\tLoss: 0.583605\n",
      "\n",
      "Train Epoch: 18 [10000/41667 (24%)]\tLoss: 0.803691\n",
      "\n",
      "Train Epoch: 18 [20000/41667 (48%)]\tLoss: 0.702099\n",
      "\n",
      "Train Epoch: 18 [30000/41667 (72%)]\tLoss: 0.801462\n",
      "\n",
      "Train Epoch: 18 [40000/41667 (96%)]\tLoss: 0.679239\n",
      "\tAccuracy: 78.01%\n",
      "\n",
      "Train Epoch: 19 [0/41667 (0%)]\tLoss: 0.554523\n",
      "\n",
      "Train Epoch: 19 [10000/41667 (24%)]\tLoss: 0.447008\n",
      "\n",
      "Train Epoch: 19 [20000/41667 (48%)]\tLoss: 0.546935\n",
      "\n",
      "Train Epoch: 19 [30000/41667 (72%)]\tLoss: 0.585107\n",
      "\n",
      "Train Epoch: 19 [40000/41667 (96%)]\tLoss: 0.634314\n",
      "\tAccuracy: 79.17%\n",
      "\n",
      "Train Epoch: 20 [0/41667 (0%)]\tLoss: 0.537353\n",
      "\n",
      "Train Epoch: 20 [10000/41667 (24%)]\tLoss: 0.441186\n",
      "\n",
      "Train Epoch: 20 [20000/41667 (48%)]\tLoss: 0.549739\n",
      "\n",
      "Train Epoch: 20 [30000/41667 (72%)]\tLoss: 0.707240\n",
      "\n",
      "Train Epoch: 20 [40000/41667 (96%)]\tLoss: 0.498839\n",
      "\tAccuracy: 79.90%\n",
      "\n",
      "Train Epoch: 21 [0/41667 (0%)]\tLoss: 0.505702\n",
      "\n",
      "Train Epoch: 21 [10000/41667 (24%)]\tLoss: 0.448195\n",
      "\n",
      "Train Epoch: 21 [20000/41667 (48%)]\tLoss: 0.400591\n",
      "\n",
      "Train Epoch: 21 [30000/41667 (72%)]\tLoss: 0.562245\n",
      "\n",
      "Train Epoch: 21 [40000/41667 (96%)]\tLoss: 0.598286\n",
      "\tAccuracy: 81.92%\n",
      "\n",
      "Train Epoch: 22 [0/41667 (0%)]\tLoss: 0.384652\n",
      "\n",
      "Train Epoch: 22 [10000/41667 (24%)]\tLoss: 0.347546\n",
      "\n",
      "Train Epoch: 22 [20000/41667 (48%)]\tLoss: 0.411380\n",
      "\n",
      "Train Epoch: 22 [30000/41667 (72%)]\tLoss: 0.475059\n",
      "\n",
      "Train Epoch: 22 [40000/41667 (96%)]\tLoss: 0.688233\n",
      "\tAccuracy: 82.57%\n",
      "\n",
      "Train Epoch: 23 [0/41667 (0%)]\tLoss: 0.422778\n",
      "\n",
      "Train Epoch: 23 [10000/41667 (24%)]\tLoss: 0.387065\n",
      "\n",
      "Train Epoch: 23 [20000/41667 (48%)]\tLoss: 0.449084\n",
      "\n",
      "Train Epoch: 23 [30000/41667 (72%)]\tLoss: 0.560018\n",
      "\n",
      "Train Epoch: 23 [40000/41667 (96%)]\tLoss: 0.343204\n",
      "\tAccuracy: 82.94%\n",
      "\n",
      "Train Epoch: 24 [0/41667 (0%)]\tLoss: 0.371881\n",
      "\n",
      "Train Epoch: 24 [10000/41667 (24%)]\tLoss: 0.374993\n",
      "\n",
      "Train Epoch: 24 [20000/41667 (48%)]\tLoss: 0.644796\n",
      "\n",
      "Train Epoch: 24 [30000/41667 (72%)]\tLoss: 0.498117\n",
      "\n",
      "Train Epoch: 24 [40000/41667 (96%)]\tLoss: 0.622943\n",
      "\tAccuracy: 83.66%\n",
      "\n",
      "Train Epoch: 25 [0/41667 (0%)]\tLoss: 0.276372\n",
      "\n",
      "Train Epoch: 25 [10000/41667 (24%)]\tLoss: 0.303999\n",
      "\n",
      "Train Epoch: 25 [20000/41667 (48%)]\tLoss: 0.422951\n",
      "\n",
      "Train Epoch: 25 [30000/41667 (72%)]\tLoss: 0.440189\n",
      "\n",
      "Train Epoch: 25 [40000/41667 (96%)]\tLoss: 0.412518\n",
      "\tAccuracy: 84.93%\n",
      "Test set: Avg. loss: -559.5475, Accuracy: 4269/8333 (51.23%)\n",
      "Saving FC model: FC(\n",
      "  (layer_list): ModuleList(\n",
      "    (0): Linear(in_features=3072, out_features=200, bias=True)\n",
      "    (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (3): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (4): Linear(in_features=200, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(fc_models):\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "    print(\"Training FC model: {}\".format(model))\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train(model, train_loader, optimizer, epoch, device)\n",
    "\n",
    "    test(model, val_loader, device)\n",
    "\n",
    "    print(\"Saving FC model: {}\".format(model))\n",
    "    save_model(model, dataset=\"CIFAR10\", filename=str(fc_model_params[i][0]) + \"x\" + str(fc_model_params[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missclassification Tracking\n",
    "\n",
    "Images tracked as tuples (batch_idx, image_idx) and can be accessed from dataset as test_dataset[batch_idx][image_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model test: FC(\n",
      "  (layer_list): ModuleList(\n",
      "    (0): Linear(in_features=3072, out_features=100, bias=True)\n",
      "    (1): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Finished\n",
      "Starting model test: FC(\n",
      "  (layer_list): ModuleList(\n",
      "    (0): Linear(in_features=3072, out_features=200, bias=True)\n",
      "    (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Finished\n",
      "Starting model test: FC(\n",
      "  (layer_list): ModuleList(\n",
      "    (0): Linear(in_features=3072, out_features=100, bias=True)\n",
      "    (1): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Finished\n",
      "Starting model test: FC(\n",
      "  (layer_list): ModuleList(\n",
      "    (0): Linear(in_features=3072, out_features=200, bias=True)\n",
      "    (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (3): Linear(in_features=200, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Finished\n",
      "Starting model test: FC(\n",
      "  (layer_list): ModuleList(\n",
      "    (0): Linear(in_features=3072, out_features=100, bias=True)\n",
      "    (1): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Finished\n",
      "Starting model test: FC(\n",
      "  (layer_list): ModuleList(\n",
      "    (0): Linear(in_features=3072, out_features=200, bias=True)\n",
      "    (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (3): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (4): Linear(in_features=200, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Finished\n",
      "Starting model test: CifarResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "Finished\n",
      "Starting model test: VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Finished\n",
      "Starting model test: MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): ConvBNActivation(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNActivation(\n",
      "          (0): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNActivation(\n",
      "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNActivation(\n",
      "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNActivation(\n",
      "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
      "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(288, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNActivation(\n",
      "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNActivation(\n",
      "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNActivation(\n",
      "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNActivation(\n",
      "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): ConvBNActivation(\n",
      "      (0): Conv2d(160, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Finished\n",
      "Starting model test: ShuffleNetV2(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (stage2): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage3): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage4): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(192, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n",
      "Finished\n",
      "Starting model test: RepVGG(\n",
      "  (stage0): RepVGGBlock(\n",
      "    (nonlinearity): ReLU()\n",
      "    (rbr_dense): Sequential(\n",
      "      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (rbr_1x1): Sequential(\n",
      "      (conv): Conv2d(3, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (stage1): Sequential(\n",
      "    (0): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_identity): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_identity): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage2): Sequential(\n",
      "    (0): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_identity): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_identity): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_identity): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage3): Sequential(\n",
      "    (0): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_identity): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_identity): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_identity): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_identity): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_identity): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_identity): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_identity): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_identity): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_identity): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_identity): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_identity): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_identity): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_identity): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage4): Sequential(\n",
      "    (0): RepVGGBlock(\n",
      "      (nonlinearity): ReLU()\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(192, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(192, 1280, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (gap): AdaptiveAvgPool2d(output_size=1)\n",
      "  (linear): Linear(in_features=1280, out_features=10, bias=True)\n",
      ")\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "misses = dict()\n",
    "complex_list = list(complex_models.values())\n",
    "for model in fc_models + complex_list:\n",
    "    print(\"Starting model test: {}\".format(model))\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i, (data, target) in enumerate(test_loader):\n",
    "\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "            missed = pred.not_equal(target.data.view_as(pred)).view(-1).cpu().numpy()\n",
    "\n",
    "            for j, miss in enumerate(missed):\n",
    "                if miss:\n",
    "                    if (i, j) in misses:\n",
    "                        misses[(i, j)] += 1\n",
    "                    else:\n",
    "                        misses[(i, j)] = 1\n",
    "\n",
    "    print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2477\n",
      "7978\n"
     ]
    }
   ],
   "source": [
    "all_miss = {k: v for k, v in misses.items() if v > 0}\n",
    "significant = {k: v for k, v in misses.items() if v > 5}\n",
    "print(len(significant))\n",
    "print(len(all_miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = all_miss.values()\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8), facecolor=\"w\")\n",
    "plt.hist(y, [x-0.5 for x in range(11)], edgecolor=\"k\")\n",
    "plt.xlabel(\"Number of Missclassifications\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"plots/CIFAR/im_freq.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in significant:\n",
    "\n",
    "    idx = sample[0]*test_batch_size + sample[1]\n",
    "    im_net = test_loader.dataset[idx][0].view(3, 32, 32)\n",
    "    im_raw = raw_test_loader.dataset[idx][0].view(3, 32, 32)\n",
    "    label = test_loader.dataset[idx][1]\n",
    "\n",
    "    preds = np.array([model(im_net.unsqueeze(0).to(device)).argmax(dim=1, keepdim=True).cpu().numpy() for model in fc_models + complex_list]).flatten()\n",
    "    fig = plt.figure(figsize=(12, 8), facecolor=\"w\")\n",
    "    plt.hist(preds, [x-0.5 for x in range(10)], edgecolor=\"k\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"True Label: {}\".format(label))\n",
    "    plt.savefig(\"plots/CIFAR/images/im_\" + str(idx) + \"_freq.png\")\n",
    "    plt.close()\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(im_raw.squeeze().cpu().numpy().transpose((1,2,0)))\n",
    "    plt.title(\"Actual: {}\".format(test_loader.dataset.targets[idx]))\n",
    "    plt.savefig(\"plots/CIFAR/images/im_\" + str(idx) + \".png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2477.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(len(os.listdir(\"plots/CIFAR/images\"))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5ee8f78cef944f1f3500638b1c2795c8c18c20511be49981a28179c91d51f11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
